{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52443fdc",
   "metadata": {},
   "source": [
    "\\begin{exercise}\n",
    "Apply the following MAP estimators to 2D data.\n",
    "\n",
    "__Read material of chapter 3 and 4 in the probabilistic machine learning: an introduction__\n",
    "\\end{exercise}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e7af9f",
   "metadata": {},
   "source": [
    "A 2D Gaussian distribution is a probability distribution in two dimensions that has a bell-shaped or Gaussian curve when plotted. It is also known as a normal distribution or a Gaussian function. \n",
    "\n",
    "In mathematical terms, a 2D Gaussian distribution is defined by two parameters: the **mean** and the **covariance matrix**. The mean is a vector that represents the center of the distribution, and the covariance matrix describes the shape and orientation of the distribution. The formula for a 2D Gaussian distribution is as follows:\n",
    "$$\n",
    "f(x, y)=1 /(2 \\pi \\sigma_x \\sigma_y)*e ^{-(x-\\mu_{x})^2/(2\\sigma_x^2) - (y-\\mu_y)^2)/(2\\sigma_y^2)}\n",
    "$$\n",
    "where \n",
    "- x and y are the variables of the distribution, \n",
    "- $\\mu_x$ and $\\mu_y$ are the means, \n",
    "- $\\sigma_x$ and $\\sigma_y$ are the standard deviations, \n",
    "- $\\pi$ is the mathematical constant pi, and \n",
    "- $e$ is the exponential function.\n",
    "\n",
    "The value of f(x,y) gives the probability density at point (x,y) in the distribution. The bell-shaped curve represents the probability density function of the distribution, and it is symmetrical around the mean. The covariance matrix describes the spread and correlation of the distribution in both dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "378018e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the mean vector and covariance matrix\n",
    "mean = np.array([0, 0])\n",
    "cov = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "# Define a grid of points to evaluate the distribution\n",
    "x, y = np.meshgrid(np.linspace(-3, 3, 100), np.linspace(-3, 3, 100))\n",
    "pos = np.dstack((x, y))\n",
    "\n",
    "# Evaluate the 2D Gaussian distribution at each point in the grid\n",
    "z = np.zeros_like(x)\n",
    "for i in range(x.shape[0]):\n",
    "    for j in range(x.shape[1]):\n",
    "        point = np.array([x[i,j], y[i,j]])\n",
    "        z[i,j] = 1/(2*np.pi*np.sqrt(np.linalg.det(cov))) * \\\n",
    "                 np.exp(-0.5 * (point-mean) @ np.linalg.inv(cov) @ (point-mean).T)\n",
    "\n",
    "# Plot the 2D Gaussian distribution\n",
    "fig, ax = plt.subplots()\n",
    "ax.contourf(x, y, z, levels=50)\n",
    "ax.set_aspect('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f2d86",
   "metadata": {
    "variables": {
     "-1 / 2}{(x-\\mu)^T \\Sigma^{-1}(x-\\mu)": "<p><strong>SyntaxError</strong>: invalid syntax (<ipython-input-1-1db632002496>, line 1)</p>\n"
    }
   },
   "source": [
    "\n",
    "A multivariate Gaussian distribution, also known as a multivariate normal distribution, is a probability distribution that describes the joint probability of a set of random variables. In contrast to a univariate Gaussian distribution, which describes the probability distribution of a single random variable, a multivariate Gaussian distribution describes the probability distribution of a vector of correlated random variables.\n",
    "\n",
    "The multivariate Gaussian distribution is characterized by two parameters: a mean vector and a covariance matrix. The mean vector is a vector of expected values for each variable, and the covariance matrix describes the pairwise covariance between the variables.\n",
    "\n",
    "Mathematically, a multivariate Gaussian distribution with mean vector $\\mu$ and covariance matrix $\\Sigma$ can be written as:\n",
    "\n",
    "\n",
    "A vector-valued random variable $X=\\left[X_1 \\cdots X_n\\right]^T$ is said to have a multivariate normal (or Gaussian) distribution with mean $\\mu \\in \\mathbf{R}^n$ and covariance matrix $\\Sigma \\in \\mathbf{S}_{++}^n$ if its probability density function  is given by\n",
    "$$\n",
    "p(x ; \\mu, \\Sigma)=\\frac{1}{(2 \\pi)^{n / 2}|\\Sigma|^{1 / 2}} \\exp \\left(-\\frac{1}{2}(x-\\mu)^T \\Sigma^{-1}(x-\\mu)\\right) .\n",
    "$$\n",
    "We write this as $X \\sim \\mathcal{N}(\\mu, \\Sigma)$. In these notes, we describe multivariate Gaussians and some of their basic properties.\n",
    "\n",
    "**Proposition 1**. For any random vector $X$ with mean $\\mu$ and covariance matrix $\\Sigma$,\n",
    "$$\n",
    "\\Sigma=E\\left[(X-\\mu)(X-\\mu)^T\\right]=E\\left[X X^T\\right]-\\mu \\mu^T .\n",
    "$$\n",
    "In the definition of multivariate Gaussians, we required that the covariance matrix $\\Sigma$ be symmetric positive definite (i.e., $\\Sigma \\in \\mathbf{S}_{++}^n$ ). Why does this restriction exist? As seen in the following proposition, the covariance matrix of any random vector must always be symmetric positive semidefinite:\n",
    "\n",
    "**Proposition 2**. Suppose that $\\Sigma$ is the covariance matrix corresponding to some random vector $X$. Then $\\Sigma$ is symmetric positive semidefinite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48366d26",
   "metadata": {},
   "source": [
    "# Example 1 - Estimate mean of given data using MAP estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf7690",
   "metadata": {},
   "source": [
    "To perform a Maximum A Posteriori (MAP) estimation of the data mean in Python, you will need to make some assumptions about the prior distribution of the mean. Here, we assume a Gaussian prior distribution with mean 0 and standard deviation 1.\n",
    "First, let's generate some sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a4d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)  # for reproducibility\n",
    "data = np.random.normal(loc=2.0, scale=1.5, size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63458286",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The log likelihood of the mean is a statistical concept used in maximum likelihood estimation (MLE) to find the most likely value of the mean of a distribution that best fits a set of observed data.\n",
    "\n",
    "Given a set of observations $x_1, x_2, \\ldots, x_n$  from a distribution with an unknown mean $\\mu$ and a known variance $\\sigma^2$, the log likelihood of the mean is given by:\n",
    "\n",
    "$$\n",
    "\\log L(\\mu)=-n / 2 \\log \\left(2 \\pi \\sigma^2\\right)-\\sum(x_i-\\mu)^2 / 2 \\sigma^2\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "where n is the sample size, $\\pi$ is the mathematical constant $\\pi$, and $\\Sigma$ denotes the sum of the squared deviations of the observations from the mean.\n",
    "\n",
    "The maximum likelihood estimate of the mean is the value of $\\mu$ that maximizes the log likelihood function. In practice, this is often found by taking the derivative of the log likelihood function with respect to $\\mu$, setting it equal to zero, and solving for $\\mu$. \n",
    "\n",
    "It is important to note that the log likelihood of the mean is only one component of the maximum likelihood estimation process and must be used in conjunction with other components (such as the log likelihood of the variance) to obtain a complete estimate of the distribution parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc95846",
   "metadata": {},
   "source": [
    "Now, we can define the log-likelihood and log-prior functions. \n",
    "\n",
    "\n",
    "\n",
    "If we assume that the mean of a normal distribution follows a normal distribution with a mean of 0 and a standard deviation of 1, we can calculate the log prior of the mean as follows:\n",
    "\n",
    "Let $\\mu$ be the mean of the normal distribution. Then, we can write:\n",
    "\n",
    "$$\\mu ~ N(0, 1)$$\n",
    "\n",
    "The probability density function of a normal distribution is given by:\n",
    "\n",
    "$$f(x) = (1 / {\\sigma \\sqrt(2\\pi))} * \\exp^{-(x - \\mu)^2)/ {2\\sigma^2}}$$\n",
    "\n",
    "where $\\mu$ is the mean, $\\sigma$ is the standard deviation, and $e$ is the base of the natural logarithm.\n",
    "\n",
    "The log prior of $\\mu$ is the natural logarithm of the probability density function of $\\mu$, or:\n",
    "$$\n",
    "\\log (\\operatorname{prior}(\\mu))=\\log (f(\\mu))=\\log (1 / \\sqrt(2 \\pi))-\\left(\\mu^ 2 / 2\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "where log is the natural logarithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6605748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(data, mean):\n",
    "    return -0.5 * np.sum((data - mean)**2)\n",
    "\n",
    "def log_prior(mean):\n",
    "    return -0.5 * ((mean - 0)**2 / 1**2)  # Gaussian prior with mean 0 and std 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7a522",
   "metadata": {},
   "source": [
    "Next, we can define the log-posterior function by adding the log-likelihood and log-prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35b1d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_posterior(data, mean):\n",
    "    return log_likelihood(data, mean) + log_prior(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1106cf0",
   "metadata": {},
   "source": [
    "To find the MAP estimate of the mean, we can use the fmin function from the scipy.optimize module to minimize the negative log-posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4daf6ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 93.542502\n",
      "         Iterations: 27\n",
      "         Function evaluations: 54\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import fmin\n",
    "\n",
    "map_estimate = fmin(lambda x: -log_posterior(data, x), x0=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c252984",
   "metadata": {},
   "source": [
    "Here, we pass a lambda function to fmin that takes a single argument x (the mean) and returns the negative log-posterior. We also set the initial guess for the mean to be 0.0.\n",
    "\n",
    "Finally, we can print the MAP estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc1e5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP estimate of mean: 1.8260000000000023\n"
     ]
    }
   ],
   "source": [
    "print(\"MAP estimate of mean:\", map_estimate[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4115bf1a",
   "metadata": {},
   "source": [
    "# Example 2 - Apply the MLE for estimating the mean of data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82371233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.05421814698072\n",
      "      fun: 224.85489933767872\n",
      " hess_inv: array([[0.04]])\n",
      "      jac: array([-3.81469727e-06])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 8\n",
      "      nit: 3\n",
      "     njev: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([5.05421797])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Generate some random data\n",
    "np.random.seed(123)\n",
    "data = np.random.normal(loc=5, scale=2, size=100)\n",
    "print(np.mean(data))\n",
    "\n",
    "# Define the likelihood function\n",
    "def likelihood(x, data):\n",
    "    return np.prod(1/np.sqrt(2*np.pi*2**2)*np.exp(-(data-x)**2/(2*2**2)))\n",
    "\n",
    "# Take the logarithm of the likelihood function\n",
    "def log_likelihood(x, data):\n",
    "    return np.sum(np.log(likelihood(x, data)))\n",
    "\n",
    "# Define the negative log-likelihood function\n",
    "def neg_log_likelihood(x, data):\n",
    "    return -log_likelihood(x, data)\n",
    "#MAP\n",
    "\n",
    "# Use maximum likelihood estimation to estimate the mean\n",
    "result = minimize(neg_log_likelihood, x0=0, args=(data,))\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4024bfcf",
   "metadata": {},
   "source": [
    "# Example 3 - Apply MLA to estimate the mean of a sample without simplifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c47f4f",
   "metadata": {},
   "source": [
    "Likelihood refers to the probability of observing a given set of data given a certain model or hypothesis. In other words, it measures how well the data fits the model. The likelihood function is defined as the probability of observing the data given a set of model parameters, which is denoted as P(data|parameters).\n",
    "\n",
    "Maximum a posteriori (MAP) estimation is a method for estimating the parameters of a statistical model. It is similar to maximum likelihood estimation, but with the additional step of incorporating prior knowledge or assumptions about the parameters. The MAP estimate is the set of parameters that maximizes the posterior probability, which is the product of the likelihood function and the prior probability distribution over the parameters.\n",
    "\n",
    "To estimate the mean using MAP optimization in Python, we can follow these steps:\n",
    "\n",
    "1. Define the likelihood function for the data. Assuming that the data follows a normal distribution with unknown mean and known variance, the likelihood function is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2f8d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(data, mean):\n",
    "    variance = 1 # assuming known variance\n",
    "    n = len(data)\n",
    "    log_likelihood = -0.5 * n * np.log(2*np.pi*variance) - 0.5 * np.sum((data-mean)**2/variance)\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a2d71",
   "metadata": {},
   "source": [
    "2. Define the prior probability distribution over the mean. For simplicity, we can assume a normal distribution with mean 0 and variance 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cbb54ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(mean):\n",
    "    prior_mean = 0\n",
    "    prior_variance = 1\n",
    "    log_prior = -0.5 * np.log(2*np.pi*prior_variance) - 0.5 * ((mean-prior_mean)**2/prior_variance)\n",
    "    return log_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8778a631",
   "metadata": {},
   "source": [
    "3. Combine the likelihood and prior to get the posterior probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c13c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(data, mean):\n",
    "    return likelihood(data, mean) + prior(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53397b7a",
   "metadata": {},
   "source": [
    "4. Use an optimization method, such as the BFGS algorithm implemented in the `scipy.optimize.minimize` function, to find the value of the mean that maximizes the posterior probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff0c4bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP estimate of the mean: 2.8380275925151013\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# generate some sample data\n",
    "data = np.random.normal(loc=3, scale=1, size=100)\n",
    "\n",
    "# define the negative posterior probability as the objective function\n",
    "neg_posterior = lambda mean: -posterior(data, mean)\n",
    "\n",
    "# find the MAP estimate using optimization\n",
    "result = minimize(neg_posterior, x0=0)\n",
    "map_estimate = result.x[0]\n",
    "\n",
    "print(\"MAP estimate of the mean:\", map_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39325901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.866407908992594"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c45a0",
   "metadata": {},
   "source": [
    "Note that in this example, we assumed that the variance of the data is known. In practice, this is often not the case, and the variance would need to be estimated as well. This can be done using maximum likelihood estimation or Bayesian methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5277ec",
   "metadata": {},
   "source": [
    "# Example - Apply MAP to determine both $\\mu$ and $\\sigma$ of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e765d3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 205.20244769763633\n",
      " hess_inv: array([[3.46594592e-02, 5.00342908e-05],\n",
      "       [5.00342908e-05, 1.67283298e-02]])\n",
      "      jac: array([0., 0.])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 88\n",
      "      nit: 21\n",
      "     njev: 28\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([10.23683157,  1.8624024 ])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enh\\anaconda3\\envs\\py36\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:497: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n",
      "C:\\Users\\enh\\anaconda3\\envs\\py36\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:497: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# define log-likelihood and log-prior functions\n",
    "def log_likelihood(theta, data):\n",
    "    \"\"\"Log-likelihood function for a given parameter theta\"\"\"\n",
    "    mu = theta[0]\n",
    "    sigma = theta[1]\n",
    "    N = len(data)\n",
    "    return -N/2 * np.log(2*np.pi) - N/2 * np.log(sigma**2) \\\n",
    "           - np.sum((data - mu)**2) / (2*sigma**2)\n",
    "\n",
    "def log_prior(theta):\n",
    "    \"\"\"Log-prior function for a given parameter theta\"\"\"\n",
    "    mu = theta[0]\n",
    "    sigma = theta[1]\n",
    "    if mu < 0 or sigma < 0:\n",
    "        return -np.inf  # return negative infinity for invalid values\n",
    "    return -np.log(sigma)  # use a log-uniform prior for sigma\n",
    "\n",
    "# define log-posterior function\n",
    "def log_posterior(theta, data):\n",
    "    \"\"\"Log-posterior function for a given parameter theta\"\"\"\n",
    "    return log_likelihood(theta, data) + log_prior(theta)\n",
    "\n",
    "# generate some fake data\n",
    "#data = np.random.normal(0, 1, 100)\n",
    "data = np.random.normal(loc=10, scale=2, size=100)\n",
    "\n",
    "# minimize negative log-posterior to find maximum posterior probability\n",
    "result = minimize(lambda theta: -log_posterior(theta, data), x0=[0, 1])\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
