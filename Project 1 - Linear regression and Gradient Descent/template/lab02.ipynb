{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_cost` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    e = y - tx.dot(w)\n",
    "    return 1/2 * np.mean(e**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "        \n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    for i, w0 in enumerate(grid_w0):\n",
    "        for j, w1 in enumerate(grid_w1):\n",
    "            w = np.array([w0, w1])\n",
    "            losses[i, j] = compute_loss(y, tx, w)\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=42.42448314678248, w0*=66.66666666666669, w1*=16.666666666666686, execution time=0.010 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=10)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "      l=loss_star, w0=w0_star, w1=w1_star, t=execution_time))\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0,6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "        \n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    e = y - tx.dot(w)\n",
    "    return -1/len(y) * tx.T.dot(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        \n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD \n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute gradient and loss\n",
    "        grad = compute_gradient(y, tx, w)            \n",
    "        loss = compute_loss(y, tx, w)\n",
    "\n",
    "        # update w by gradient\n",
    "        w = w - gamma * grad        \n",
    "       \n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2792.2367127591674, w0=51.305745401473324, w1=9.435798704492441\n",
      "GD iter. 1/49: loss=265.30246210896615, w0=66.69746902191562, w1=12.266538315840048\n",
      "GD iter. 2/49: loss=37.87837955044177, w0=71.31498610804832, w1=13.115760199244336\n",
      "GD iter. 3/49: loss=17.410212120174524, w0=72.70024123388814, w1=13.370526764265632\n",
      "GD iter. 4/49: loss=15.568077051450455, w0=73.11581777164008, w1=13.446956733772023\n",
      "GD iter. 5/49: loss=15.402284895265295, w0=73.24049073296567, w1=13.469885724623941\n",
      "GD iter. 6/49: loss=15.38736360120863, w0=73.27789262136332, w1=13.476764421879516\n",
      "GD iter. 7/49: loss=15.38602068474353, w0=73.28911318788263, w1=13.478828031056189\n",
      "GD iter. 8/49: loss=15.385899822261674, w0=73.29247935783842, w1=13.47944711380919\n",
      "GD iter. 9/49: loss=15.385888944638305, w0=73.29348920882516, w1=13.47963283863509\n",
      "GD iter. 10/49: loss=15.3858879656522, w0=73.29379216412119, w1=13.479688556082861\n",
      "GD iter. 11/49: loss=15.385887877543453, w0=73.29388305071, w1=13.479705271317192\n",
      "GD iter. 12/49: loss=15.385887869613667, w0=73.29391031668663, w1=13.479710285887492\n",
      "GD iter. 13/49: loss=15.385887868899983, w0=73.29391849647962, w1=13.479711790258582\n",
      "GD iter. 14/49: loss=15.38588786883575, w0=73.29392095041752, w1=13.479712241569908\n",
      "GD iter. 15/49: loss=15.385887868829974, w0=73.29392168659889, w1=13.479712376963306\n",
      "GD iter. 16/49: loss=15.38588786882945, w0=73.2939219074533, w1=13.479712417581325\n",
      "GD iter. 17/49: loss=15.385887868829403, w0=73.29392197370963, w1=13.479712429766732\n",
      "GD iter. 18/49: loss=15.3858878688294, w0=73.29392199358652, w1=13.479712433422353\n",
      "GD iter. 19/49: loss=15.385887868829403, w0=73.29392199954958, w1=13.47971243451904\n",
      "GD iter. 20/49: loss=15.385887868829398, w0=73.2939220013385, w1=13.479712434848047\n",
      "GD iter. 21/49: loss=15.3858878688294, w0=73.29392200187519, w1=13.479712434946748\n",
      "GD iter. 22/49: loss=15.3858878688294, w0=73.29392200203618, w1=13.479712434976358\n",
      "GD iter. 23/49: loss=15.3858878688294, w0=73.29392200208449, w1=13.479712434985242\n",
      "GD iter. 24/49: loss=15.3858878688294, w0=73.29392200209898, w1=13.479712434987906\n",
      "GD iter. 25/49: loss=15.385887868829398, w0=73.29392200210333, w1=13.479712434988706\n",
      "GD iter. 26/49: loss=15.3858878688294, w0=73.29392200210462, w1=13.479712434988945\n",
      "GD iter. 27/49: loss=15.3858878688294, w0=73.29392200210502, w1=13.479712434989018\n",
      "GD iter. 28/49: loss=15.3858878688294, w0=73.29392200210513, w1=13.47971243498904\n",
      "GD iter. 29/49: loss=15.3858878688294, w0=73.29392200210518, w1=13.479712434989047\n",
      "GD iter. 30/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.007 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fcabd9b3f34b2eb88b64adf2378f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses, gd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from just few examples n and their corresponding y_n labels.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "        \n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(y)\n",
    "    random_index = np.random.randint(n, size=1)\n",
    "    y_n = y[random_index]\n",
    "    tx_n = tx[random_index]\n",
    "    e = y_n - tx_n.dot(w)\n",
    "    return -1/n * tx_n.T.dot(e)\n",
    "    \n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "            \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        \n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    \n",
    "    for n_iter in range(max_iters):\n",
    "        # implement stochastic gradient descent.\n",
    "        indices = np.random.choice(len(y), size=batch_size, replace=False)\n",
    "        batch_y = y[indices]\n",
    "        batch_tx = tx[indices, :]\n",
    "        grad = compute_stoch_gradient(batch_y, batch_tx, w)\n",
    "        \n",
    "        # update the model parameters using the gradient and the stepsize\n",
    "        w = w - gamma * grad\n",
    "        \n",
    "        # compute the loss using the updated model parameters and store it\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # store the updated model parameters\n",
    "        ws.append(w)\n",
    "\n",
    "        print(\"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=2045.4080358018311, w0=10.3062578158784, w1=23.10252160015103\n",
      "SGD iter. 1/49: loss=1674.865549591694, w0=16.681488026939185, w1=24.156399320591607\n",
      "SGD iter. 2/49: loss=1227.2540616033646, w0=24.07494037265127, w1=14.587951952668991\n",
      "SGD iter. 3/49: loss=987.2460762587275, w0=29.325830521383022, w1=10.23513105634509\n",
      "SGD iter. 4/49: loss=784.7671255615154, w0=34.10039159724615, w1=15.101331930666724\n",
      "SGD iter. 5/49: loss=658.4690643984245, w0=38.14964157749616, w1=20.624354238161\n",
      "SGD iter. 6/49: loss=511.1449497279432, w0=42.3316631785428, w1=19.211784683396257\n",
      "SGD iter. 7/49: loss=434.3696653914403, w0=45.22609559892657, w1=20.56241502977944\n",
      "SGD iter. 8/49: loss=312.49254134687993, w0=49.52677718358913, w1=18.895996597751008\n",
      "SGD iter. 9/49: loss=248.47494221743565, w0=52.03562013500181, w1=17.256312814208584\n",
      "SGD iter. 10/49: loss=203.307916982818, w0=54.12484301491756, w1=16.376343065728616\n",
      "SGD iter. 11/49: loss=192.3833130291068, w0=54.94372880621412, w1=17.634861047737775\n",
      "SGD iter. 12/49: loss=175.15141403826775, w0=56.369963306819514, w1=19.233899990078022\n",
      "SGD iter. 13/49: loss=157.24595964447252, w0=57.83833985963043, w1=20.176362656443157\n",
      "SGD iter. 14/49: loss=140.30793032923734, w0=58.97879298971505, w1=20.182037873181518\n",
      "SGD iter. 15/49: loss=135.83305027281781, w0=59.67735065268034, w1=20.928424370216433\n",
      "SGD iter. 16/49: loss=139.85998180396987, w0=58.85323078625775, w1=19.83696223964729\n",
      "SGD iter. 17/49: loss=140.03827679034538, w0=58.467059281893064, w1=18.908240754802407\n",
      "SGD iter. 18/49: loss=86.82714998073699, w0=61.34322940557731, w1=13.731646329312408\n",
      "SGD iter. 19/49: loss=76.27467074132257, w0=62.37920903030925, w1=15.106551851863278\n",
      "SGD iter. 20/49: loss=74.00159508666479, w0=62.64077286278016, w1=15.414092917461181\n",
      "SGD iter. 21/49: loss=64.4574427293654, w0=63.828998918548585, w1=16.40517662780175\n",
      "SGD iter. 22/49: loss=48.768515220567174, w0=65.26986574770093, w1=15.022364673710225\n",
      "SGD iter. 23/49: loss=49.31965883298967, w0=65.19455236049666, w1=14.985618586417685\n",
      "SGD iter. 24/49: loss=45.49294092048884, w0=65.80977917478683, w1=15.529520290281326\n",
      "SGD iter. 25/49: loss=34.087350059188296, w0=67.26219201792189, w1=12.4691889178842\n",
      "SGD iter. 26/49: loss=32.79016002875882, w0=67.75630562606084, w1=11.444190587495324\n",
      "SGD iter. 27/49: loss=29.31405990056033, w0=68.26680281920619, w1=11.872100297565728\n",
      "SGD iter. 28/49: loss=21.0695522162967, w0=69.92899446793184, w1=13.268545712476506\n",
      "SGD iter. 29/49: loss=21.48867204343089, w0=69.80210221351683, w1=13.366739370828881\n",
      "SGD iter. 30/49: loss=21.336162472974454, w0=69.84421988652299, w1=13.469488832990677\n",
      "SGD iter. 31/49: loss=20.4452593177043, w0=70.11296012807011, w1=13.464730656554607\n",
      "SGD iter. 32/49: loss=19.50335792501495, w0=70.42494583966979, w1=13.417135348539283\n",
      "SGD iter. 33/49: loss=18.81101789908511, w0=70.67914775568788, w1=13.594671996506168\n",
      "SGD iter. 34/49: loss=17.501103073776285, w0=71.24127364495517, w1=13.610346013302998\n",
      "SGD iter. 35/49: loss=17.55351152420749, w0=71.21744401372709, w1=13.632965410612432\n",
      "SGD iter. 36/49: loss=16.93242038538634, w0=71.54044539375802, w1=13.6153030581648\n",
      "SGD iter. 37/49: loss=17.19188997333014, w0=71.39606441645695, w1=13.580413942420286\n",
      "SGD iter. 38/49: loss=16.8231601558497, w0=71.69138198211473, w1=14.03325562063005\n",
      "SGD iter. 39/49: loss=17.303191536250843, w0=71.50721417363461, w1=14.281137709437528\n",
      "SGD iter. 40/49: loss=17.024405028244306, w0=71.68542710655915, w1=14.310241477125528\n",
      "SGD iter. 41/49: loss=17.102816107440017, w0=71.55744429253677, w1=14.126629463203068\n",
      "SGD iter. 42/49: loss=15.887987854428461, w0=72.32916028028005, w1=13.750700979579241\n",
      "SGD iter. 43/49: loss=15.750626784105052, w0=73.13113436941651, w1=14.318150278359038\n",
      "SGD iter. 44/49: loss=15.73387622690184, w0=72.94500831303534, w1=14.237496014729697\n",
      "SGD iter. 45/49: loss=16.161319279787193, w0=72.07321917899684, w1=13.726182391719837\n",
      "SGD iter. 46/49: loss=15.465208319336906, w0=73.05843568513244, w1=13.800939917520692\n",
      "SGD iter. 47/49: loss=15.855412250349863, w0=73.86142412999692, w1=14.265199607309059\n",
      "SGD iter. 48/49: loss=15.426344453201548, w0=73.46064307921395, w1=13.710184236283665\n",
      "SGD iter. 49/49: loss=15.528155655118322, w0=72.80256288538413, w1=13.272102726658858\n",
      "SGD: execution time=0.030 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0800b11f20d04225a48267ef6c06ad57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses, sgd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# reload the data by subsampling first, then by subsampling and adding outliers\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2792.2367127591674, w0=51.305745401473324, w1=9.435798704492441\n",
      "GD iter. 1/49: loss=265.30246210896615, w0=66.69746902191562, w1=12.266538315840048\n",
      "GD iter. 2/49: loss=37.87837955044177, w0=71.31498610804832, w1=13.115760199244336\n",
      "GD iter. 3/49: loss=17.410212120174524, w0=72.70024123388814, w1=13.370526764265632\n",
      "GD iter. 4/49: loss=15.568077051450455, w0=73.11581777164008, w1=13.446956733772023\n",
      "GD iter. 5/49: loss=15.402284895265295, w0=73.24049073296567, w1=13.469885724623941\n",
      "GD iter. 6/49: loss=15.38736360120863, w0=73.27789262136332, w1=13.476764421879516\n",
      "GD iter. 7/49: loss=15.38602068474353, w0=73.28911318788263, w1=13.478828031056189\n",
      "GD iter. 8/49: loss=15.385899822261674, w0=73.29247935783842, w1=13.47944711380919\n",
      "GD iter. 9/49: loss=15.385888944638305, w0=73.29348920882516, w1=13.47963283863509\n",
      "GD iter. 10/49: loss=15.3858879656522, w0=73.29379216412119, w1=13.479688556082861\n",
      "GD iter. 11/49: loss=15.385887877543453, w0=73.29388305071, w1=13.479705271317192\n",
      "GD iter. 12/49: loss=15.385887869613667, w0=73.29391031668663, w1=13.479710285887492\n",
      "GD iter. 13/49: loss=15.385887868899983, w0=73.29391849647962, w1=13.479711790258582\n",
      "GD iter. 14/49: loss=15.38588786883575, w0=73.29392095041752, w1=13.479712241569908\n",
      "GD iter. 15/49: loss=15.385887868829974, w0=73.29392168659889, w1=13.479712376963306\n",
      "GD iter. 16/49: loss=15.38588786882945, w0=73.2939219074533, w1=13.479712417581325\n",
      "GD iter. 17/49: loss=15.385887868829403, w0=73.29392197370963, w1=13.479712429766732\n",
      "GD iter. 18/49: loss=15.3858878688294, w0=73.29392199358652, w1=13.479712433422353\n",
      "GD iter. 19/49: loss=15.385887868829403, w0=73.29392199954958, w1=13.47971243451904\n",
      "GD iter. 20/49: loss=15.385887868829398, w0=73.2939220013385, w1=13.479712434848047\n",
      "GD iter. 21/49: loss=15.3858878688294, w0=73.29392200187519, w1=13.479712434946748\n",
      "GD iter. 22/49: loss=15.3858878688294, w0=73.29392200203618, w1=13.479712434976358\n",
      "GD iter. 23/49: loss=15.3858878688294, w0=73.29392200208449, w1=13.479712434985242\n",
      "GD iter. 24/49: loss=15.3858878688294, w0=73.29392200209898, w1=13.479712434987906\n",
      "GD iter. 25/49: loss=15.385887868829398, w0=73.29392200210333, w1=13.479712434988706\n",
      "GD iter. 26/49: loss=15.3858878688294, w0=73.29392200210462, w1=13.479712434988945\n",
      "GD iter. 27/49: loss=15.3858878688294, w0=73.29392200210502, w1=13.479712434989018\n",
      "GD iter. 28/49: loss=15.3858878688294, w0=73.29392200210513, w1=13.47971243498904\n",
      "GD iter. 29/49: loss=15.3858878688294, w0=73.29392200210518, w1=13.479712434989047\n",
      "GD iter. 30/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.019 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points and the model fit\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16742a6fd95466da8cd68022068c150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses, gd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "        \n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    # compute subgradient gradient vector for MAE\n",
    "    N = len(y)\n",
    "    e = y - tx.dot(w)\n",
    "    return -1/N * tx.T.dot(np.sign(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "        \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        \n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD \n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute subgradient and loss\n",
    "        grad = compute_subgradient_mae(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "       \n",
    "        # update w by subgradient\n",
    "        w = w - gamma * grad\n",
    "        \n",
    "        \n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=2792.2367127591674, w0=0.7, w1=-1.5529755259535704e-15\n",
      "SubGD iter. 1/499: loss=2741.1759673576935, w0=1.4, w1=-3.1059510519071408e-15\n",
      "SubGD iter. 2/499: loss=2690.6052219562202, w0=2.0999999999999996, w1=-4.658926577860711e-15\n",
      "SubGD iter. 3/499: loss=2640.5244765547463, w0=2.8, w1=-6.2119021038142816e-15\n",
      "SubGD iter. 4/499: loss=2590.9337311532727, w0=3.5, w1=-7.764877629767851e-15\n",
      "SubGD iter. 5/499: loss=2541.8329857517992, w0=4.2, w1=-9.317853155721422e-15\n",
      "SubGD iter. 6/499: loss=2493.2222403503256, w0=4.9, w1=-1.0870828681674993e-14\n",
      "SubGD iter. 7/499: loss=2445.1014949488517, w0=5.6000000000000005, w1=-1.2423804207628563e-14\n",
      "SubGD iter. 8/499: loss=2397.4707495473785, w0=6.300000000000001, w1=-1.3976779733582134e-14\n",
      "SubGD iter. 9/499: loss=2350.3300041459047, w0=7.000000000000001, w1=-1.5529755259535703e-14\n",
      "SubGD iter. 10/499: loss=2303.679258744431, w0=7.700000000000001, w1=-1.7082730785489272e-14\n",
      "SubGD iter. 11/499: loss=2257.5185133429572, w0=8.4, w1=-1.863570631144284e-14\n",
      "SubGD iter. 12/499: loss=2211.8477679414837, w0=9.1, w1=-2.018868183739641e-14\n",
      "SubGD iter. 13/499: loss=2166.6670225400103, w0=9.799999999999999, w1=-2.174165736334998e-14\n",
      "SubGD iter. 14/499: loss=2121.9762771385367, w0=10.499999999999998, w1=-2.3294632889303548e-14\n",
      "SubGD iter. 15/499: loss=2077.775531737063, w0=11.199999999999998, w1=-2.4847608415257117e-14\n",
      "SubGD iter. 16/499: loss=2034.0647863355898, w0=11.899999999999997, w1=-2.6400583941210686e-14\n",
      "SubGD iter. 17/499: loss=1990.8440409341165, w0=12.599999999999996, w1=-2.7953559467164255e-14\n",
      "SubGD iter. 18/499: loss=1948.1132955326423, w0=13.299999999999995, w1=-2.9506534993117824e-14\n",
      "SubGD iter. 19/499: loss=1905.872550131169, w0=13.999999999999995, w1=-3.105951051907139e-14\n",
      "SubGD iter. 20/499: loss=1864.1218047296957, w0=14.699999999999994, w1=-3.261248604502496e-14\n",
      "SubGD iter. 21/499: loss=1822.861059328222, w0=15.399999999999993, w1=-3.416546157097853e-14\n",
      "SubGD iter. 22/499: loss=1782.0903139267482, w0=16.099999999999994, w1=-3.57184370969321e-14\n",
      "SubGD iter. 23/499: loss=1741.8095685252745, w0=16.799999999999994, w1=-3.727141262288567e-14\n",
      "SubGD iter. 24/499: loss=1702.0188231238012, w0=17.499999999999993, w1=-3.882438814883924e-14\n",
      "SubGD iter. 25/499: loss=1662.7180777223275, w0=18.199999999999992, w1=-4.0377363674792807e-14\n",
      "SubGD iter. 26/499: loss=1623.9073323208538, w0=18.89999999999999, w1=-4.1930339200746376e-14\n",
      "SubGD iter. 27/499: loss=1585.5865869193801, w0=19.59999999999999, w1=-4.3483314726699945e-14\n",
      "SubGD iter. 28/499: loss=1547.755841517907, w0=20.29999999999999, w1=-4.5036290252653514e-14\n",
      "SubGD iter. 29/499: loss=1510.4150961164335, w0=20.99999999999999, w1=-4.658926577860708e-14\n",
      "SubGD iter. 30/499: loss=1473.5643507149596, w0=21.69999999999999, w1=-4.814224130456065e-14\n",
      "SubGD iter. 31/499: loss=1437.203605313486, w0=22.399999999999988, w1=-4.969521683051422e-14\n",
      "SubGD iter. 32/499: loss=1401.3328599120125, w0=23.099999999999987, w1=-5.124819235646779e-14\n",
      "SubGD iter. 33/499: loss=1365.9521145105389, w0=23.799999999999986, w1=-5.280116788242136e-14\n",
      "SubGD iter. 34/499: loss=1331.0613691090653, w0=24.499999999999986, w1=-5.435414340837493e-14\n",
      "SubGD iter. 35/499: loss=1296.6606237075916, w0=25.199999999999985, w1=-5.59071189343285e-14\n",
      "SubGD iter. 36/499: loss=1262.749878306118, w0=25.899999999999984, w1=-5.746009446028207e-14\n",
      "SubGD iter. 37/499: loss=1229.3291329046444, w0=26.599999999999984, w1=-5.901306998623565e-14\n",
      "SubGD iter. 38/499: loss=1196.398387503171, w0=27.299999999999983, w1=-6.056604551218922e-14\n",
      "SubGD iter. 39/499: loss=1163.9576421016975, w0=27.999999999999982, w1=-6.21190210381428e-14\n",
      "SubGD iter. 40/499: loss=1132.006896700224, w0=28.69999999999998, w1=-6.367199656409637e-14\n",
      "SubGD iter. 41/499: loss=1100.5461512987501, w0=29.39999999999998, w1=-6.522497209004995e-14\n",
      "SubGD iter. 42/499: loss=1069.5754058972768, w0=30.099859999999982, w1=0.0004404657702421764\n",
      "SubGD iter. 43/499: loss=1039.094770399767, w0=30.799719999999983, w1=0.0008809315405495777\n",
      "SubGD iter. 44/499: loss=1009.1039391158675, w0=31.499579999999984, w1=0.001321397310856979\n",
      "SubGD iter. 45/499: loss=979.6029120455783, w0=32.19929999999999, w1=0.002151200058803724\n",
      "SubGD iter. 46/499: loss=950.5921950374303, w0=32.899019999999986, w1=0.002981002806750469\n",
      "SubGD iter. 47/499: loss=922.0710867962553, w0=33.59859999999998, w1=0.004238399708372432\n",
      "SubGD iter. 48/499: loss=894.0393825319994, w0=34.298039999999986, w1=0.005823822408791713\n",
      "SubGD iter. 49/499: loss=866.498131601995, w0=34.99747999999999, w1=0.0074092451092109945\n",
      "SubGD iter. 50/499: loss=839.4460994991558, w0=35.69691999999999, w1=0.008994667809630276\n",
      "SubGD iter. 51/499: loss=812.8832862234815, w0=36.39607999999999, w1=0.011248049853488248\n",
      "SubGD iter. 52/499: loss=786.8110265218206, w0=37.09495999999999, w1=0.014269124444697119\n",
      "SubGD iter. 53/499: loss=761.2273946584986, w0=37.793699999999994, w1=0.01766349946233946\n",
      "SubGD iter. 54/499: loss=736.1321497394637, w0=38.49215999999999, w1=0.021587972991156293\n",
      "SubGD iter. 55/499: loss=711.5277641117286, w0=39.19019999999999, w1=0.026549981650513393\n",
      "SubGD iter. 56/499: loss=687.4116050652249, w0=39.88739999999999, w1=0.0334590206309035\n",
      "SubGD iter. 57/499: loss=663.7846094489672, w0=40.584039999999995, w1=0.04155352991358485\n",
      "SubGD iter. 58/499: loss=640.6461355436811, w0=41.28025999999999, w1=0.05080738787870366\n",
      "SubGD iter. 59/499: loss=617.9909106434988, w0=41.97507999999999, w1=0.06316953459264504\n",
      "SubGD iter. 60/499: loss=595.8226317443318, w0=42.667939999999994, w1=0.0797066345318716\n",
      "SubGD iter. 61/499: loss=574.1413523916076, w0=43.35925999999999, w1=0.09929003796957597\n",
      "SubGD iter. 62/499: loss=552.9457342202995, w0=44.04889999999999, w1=0.12249682042556717\n",
      "SubGD iter. 63/499: loss=532.2291483076068, w0=44.735739999999986, w1=0.15117673515145405\n",
      "SubGD iter. 64/499: loss=511.9956994524344, w0=45.41991999999998, w1=0.1848471294408023\n",
      "SubGD iter. 65/499: loss=492.24260342184675, w0=46.10073999999998, w1=0.22490170464881898\n",
      "SubGD iter. 66/499: loss=472.9654653172095, w0=46.77847999999998, w1=0.27030807598900264\n",
      "SubGD iter. 67/499: loss=454.16440191211626, w0=47.45243999999998, w1=0.32205641313644706\n",
      "SubGD iter. 68/499: loss=435.83893989608976, w0=48.119959999999985, w1=0.3843602843516495\n",
      "SubGD iter. 69/499: loss=417.9941932851492, w0=48.78257999999998, w1=0.45460143187065083\n",
      "SubGD iter. 70/499: loss=400.61558956269056, w0=49.44141999999998, w1=0.5311991534378644\n",
      "SubGD iter. 71/499: loss=383.6888118502994, w0=50.094659999999976, w1=0.6167864550871748\n",
      "SubGD iter. 72/499: loss=367.21619897220774, w0=50.74159999999998, w1=0.7118294204257005\n",
      "SubGD iter. 73/499: loss=351.1989200489362, w0=51.382239999999975, w1=0.8163783816188553\n",
      "SubGD iter. 74/499: loss=335.6268066231425, w0=52.015879999999974, w1=0.9309819479180104\n",
      "SubGD iter. 75/499: loss=320.49874200907897, w0=52.64223999999997, w1=1.056041039445561\n",
      "SubGD iter. 76/499: loss=305.80567809909013, w0=53.261179999999975, w1=1.1909782249707368\n",
      "SubGD iter. 77/499: loss=291.5477581725216, w0=53.87353999999998, w1=1.3354326069268716\n",
      "SubGD iter. 78/499: loss=277.7032726938141, w0=54.479039999999976, w1=1.488859155423101\n",
      "SubGD iter. 79/499: loss=264.27606143143925, w0=55.07641999999998, w1=1.6526057998941344\n",
      "SubGD iter. 80/499: loss=251.26480314613596, w0=55.664699999999975, w1=1.827199911738537\n",
      "SubGD iter. 81/499: loss=238.67114612083947, w0=56.24345999999998, w1=2.013212915976214\n",
      "SubGD iter. 82/499: loss=226.48532072120682, w0=56.81479999999998, w1=2.2075986497860063\n",
      "SubGD iter. 83/499: loss=214.69689344224548, w0=57.37633999999998, w1=2.411376270974464\n",
      "SubGD iter. 84/499: loss=203.32462898551765, w0=57.92975999999998, w1=2.6230481013704767\n",
      "SubGD iter. 85/499: loss=192.34820510872876, w0=58.47407999999998, w1=2.8433267790651087\n",
      "SubGD iter. 86/499: loss=181.7660962632824, w0=59.00957999999998, w1=3.072330965520354\n",
      "SubGD iter. 87/499: loss=171.563895610903, w0=59.53569999999998, w1=3.3102924945409007\n",
      "SubGD iter. 88/499: loss=161.73877516102743, w0=60.053559999999976, w1=3.555351748353824\n",
      "SubGD iter. 89/499: loss=152.28594836144043, w0=60.559939999999976, w1=3.809170691886062\n",
      "SubGD iter. 90/499: loss=143.22272548634768, w0=61.057499999999976, w1=4.069720751433983\n",
      "SubGD iter. 91/499: loss=134.5248713179193, w0=61.547919999999976, w1=4.335508393726905\n",
      "SubGD iter. 92/499: loss=126.17840315967659, w0=62.02965999999998, w1=4.6069897470010375\n",
      "SubGD iter. 93/499: loss=118.19029104383355, w0=62.502719999999975, w1=4.88502014251682\n",
      "SubGD iter. 94/499: loss=110.54527599508985, w0=62.96583999999998, w1=5.16875462665388\n",
      "SubGD iter. 95/499: loss=103.25653663589776, w0=63.41971999999998, w1=5.456484559032046\n",
      "SubGD iter. 96/499: loss=96.32191323278538, w0=63.86463999999998, w1=5.747997496770113\n",
      "SubGD iter. 97/499: loss=89.73127534938085, w0=64.30129999999998, w1=6.043221223968383\n",
      "SubGD iter. 98/499: loss=83.47021387099645, w0=64.72773999999998, w1=6.340354080836923\n",
      "SubGD iter. 99/499: loss=77.56084376992578, w0=65.14381999999998, w1=6.63994524590634\n",
      "SubGD iter. 100/499: loss=71.98917679161524, w0=65.54995999999997, w1=6.939754306256994\n",
      "SubGD iter. 101/499: loss=66.75588777663832, w0=65.94755999999997, w1=7.240382293155359\n",
      "SubGD iter. 102/499: loss=61.835025511214276, w0=66.33451999999997, w1=7.542759507922872\n",
      "SubGD iter. 103/499: loss=57.22623101138226, w0=66.71139999999997, w1=7.846017516367578\n",
      "SubGD iter. 104/499: loss=52.91994504097971, w0=67.07791999999996, w1=8.149168076773346\n",
      "SubGD iter. 105/499: loss=48.91257989137008, w0=67.43603999999996, w1=8.450471378640396\n",
      "SubGD iter. 106/499: loss=45.18991144555499, w0=67.78645999999996, w1=8.751045452661094\n",
      "SubGD iter. 107/499: loss=41.73210243602511, w0=68.12511999999997, w1=9.04921572225288\n",
      "SubGD iter. 108/499: loss=38.558795498095854, w0=68.45537999999996, w1=9.343976087699637\n",
      "SubGD iter. 109/499: loss=35.64378978904299, w0=68.77695999999996, w1=9.635092372673002\n",
      "SubGD iter. 110/499: loss=32.97791244484215, w0=69.08803999999996, w1=9.919493282073365\n",
      "SubGD iter. 111/499: loss=30.568189785039547, w0=69.38749999999996, w1=10.197623582279002\n",
      "SubGD iter. 112/499: loss=28.402007916637075, w0=69.67281999999996, w1=10.46806359361339\n",
      "SubGD iter. 113/499: loss=26.47709209553431, w0=69.94651999999996, w1=10.728826346302005\n",
      "SubGD iter. 114/499: loss=24.772125087144374, w0=70.20887999999997, w1=10.979299692022279\n",
      "SubGD iter. 115/499: loss=23.2706618888014, w0=70.45653999999996, w1=11.220392679253374\n",
      "SubGD iter. 116/499: loss=21.963519061093482, w0=70.69215999999996, w1=11.449066352016724\n",
      "SubGD iter. 117/499: loss=20.832232383774127, w0=70.91545999999995, w1=11.66451264164341\n",
      "SubGD iter. 118/499: loss=19.861903761439645, w0=71.12447999999995, w1=11.864387168308943\n",
      "SubGD iter. 119/499: loss=19.043765027666172, w0=71.31865999999995, w1=12.045105403559484\n",
      "SubGD iter. 120/499: loss=18.365766524623368, w0=71.49939999999995, w1=12.20983607316598\n",
      "SubGD iter. 121/499: loss=17.80233546400779, w0=71.66543999999995, w1=12.357476521898722\n",
      "SubGD iter. 122/499: loss=17.34157140673459, w0=71.81593999999994, w1=12.48980888194029\n",
      "SubGD iter. 123/499: loss=16.968057790272198, w0=71.95369999999994, w1=12.612418157319299\n",
      "SubGD iter. 124/499: loss=16.660085058332246, w0=72.08067999999994, w1=12.721366944472148\n",
      "SubGD iter. 125/499: loss=16.40940988815923, w0=72.19435999999995, w1=12.815458765817613\n",
      "SubGD iter. 126/499: loss=16.2110226355701, w0=72.29697999999995, w1=12.90059276939534\n",
      "SubGD iter. 127/499: loss=16.050524340148883, w0=72.38965999999995, w1=12.97576965427992\n",
      "SubGD iter. 128/499: loss=15.92171191616951, w0=72.47435999999995, w1=13.04396334930227\n",
      "SubGD iter. 129/499: loss=15.816667439315209, w0=72.55093999999995, w1=13.103277584601688\n",
      "SubGD iter. 130/499: loss=15.732750594848627, w0=72.62051999999996, w1=13.156032035188144\n",
      "SubGD iter. 131/499: loss=15.665007497656706, w0=72.68239999999996, w1=13.201870566969161\n",
      "SubGD iter. 132/499: loss=15.611465500171185, w0=72.73769999999996, w1=13.241365939188695\n",
      "SubGD iter. 133/499: loss=15.568983852672527, w0=72.78823999999996, w1=13.276636749385748\n",
      "SubGD iter. 134/499: loss=15.534364879497604, w0=72.83401999999995, w1=13.308112586749687\n",
      "SubGD iter. 135/499: loss=15.506366048557489, w0=72.87447999999995, w1=13.335151520405006\n",
      "SubGD iter. 136/499: loss=15.484302594407115, w0=72.91115999999995, w1=13.358430829065458\n",
      "SubGD iter. 137/499: loss=15.466495857924906, w0=72.94447999999996, w1=13.379256780851263\n",
      "SubGD iter. 138/499: loss=15.451988394471183, w0=72.97401999999995, w1=13.396406376905544\n",
      "SubGD iter. 139/499: loss=15.440526463961575, w0=73.00103999999995, w1=13.41218912045937\n",
      "SubGD iter. 140/499: loss=15.431057501410525, w0=73.02483999999994, w1=13.425274895313084\n",
      "SubGD iter. 141/499: loss=15.423572153620873, w0=73.04625999999995, w1=13.436222021322303\n",
      "SubGD iter. 142/499: loss=15.417501810513242, w0=73.06613999999995, w1=13.447440046601253\n",
      "SubGD iter. 143/499: loss=15.412350942597064, w0=73.08405999999995, w1=13.457856669597893\n",
      "SubGD iter. 144/499: loss=15.408147736033625, w0=73.10029999999995, w1=13.467335162734873\n",
      "SubGD iter. 145/499: loss=15.40470920711325, w0=73.11401999999995, w1=13.475393628220223\n",
      "SubGD iter. 146/499: loss=15.402079560056087, w0=73.12619999999995, w1=13.482212864437892\n",
      "SubGD iter. 147/499: loss=15.39995632989821, w0=73.13697999999995, w1=13.48799725691146\n",
      "SubGD iter. 148/499: loss=15.398237583978943, w0=73.14747999999994, w1=13.493479439140252\n",
      "SubGD iter. 149/499: loss=15.396705264021346, w0=73.15699999999994, w1=13.498468271254364\n",
      "SubGD iter. 150/499: loss=15.395437576856661, w0=73.16595999999994, w1=13.50294680429713\n",
      "SubGD iter. 151/499: loss=15.394344923779366, w0=73.17365999999994, w1=13.506576029236252\n",
      "SubGD iter. 152/499: loss=15.39348016975252, w0=73.18009999999994, w1=13.509768665455107\n",
      "SubGD iter. 153/499: loss=15.39281728140594, w0=73.18597999999994, w1=13.512571468366584\n",
      "SubGD iter. 154/499: loss=15.392253464775896, w0=73.19143999999994, w1=13.515117410468855\n",
      "SubGD iter. 155/499: loss=15.391765905351512, w0=73.19605999999995, w1=13.517185961787685\n",
      "SubGD iter. 156/499: loss=15.391378487162786, w0=73.19969999999995, w1=13.518069930874283\n",
      "SubGD iter. 157/499: loss=15.391062410415051, w0=73.20291999999995, w1=13.518854137767013\n",
      "SubGD iter. 158/499: loss=15.39079458747116, w0=73.20599999999995, w1=13.51952983926887\n",
      "SubGD iter. 159/499: loss=15.39054572089829, w0=73.20907999999994, w1=13.520205540770727\n",
      "SubGD iter. 160/499: loss=15.390306797297937, w0=73.21201999999994, w1=13.521000216270515\n",
      "SubGD iter. 161/499: loss=15.390094178245397, w0=73.21495999999993, w1=13.521794891770304\n",
      "SubGD iter. 162/499: loss=15.38989083430201, w0=73.21747999999994, w1=13.522407209546943\n",
      "SubGD iter. 163/499: loss=15.389720980559604, w0=73.21985999999994, w1=13.522732908460886\n",
      "SubGD iter. 164/499: loss=15.38955583947619, w0=73.22181999999994, w1=13.522991164028737\n",
      "SubGD iter. 165/499: loss=15.389423742376838, w0=73.22363999999993, w1=13.523086524955808\n",
      "SubGD iter. 166/499: loss=15.389298304579585, w0=73.22503999999994, w1=13.522757010157395\n",
      "SubGD iter. 167/499: loss=15.389186651662126, w0=73.22643999999994, w1=13.522427495358983\n",
      "SubGD iter. 168/499: loss=15.38907706732467, w0=73.22783999999994, w1=13.52209798056057\n",
      "SubGD iter. 169/499: loss=15.388969551567214, w0=73.22895999999994, w1=13.522225963141242\n",
      "SubGD iter. 170/499: loss=15.388901599726136, w0=73.23007999999994, w1=13.522353945721914\n",
      "SubGD iter. 171/499: loss=15.388834918664594, w0=73.23119999999994, w1=13.522481928302586\n",
      "SubGD iter. 172/499: loss=15.388769508382593, w0=73.23189999999994, w1=13.523013495747021\n",
      "SubGD iter. 173/499: loss=15.388748724133356, w0=73.23273999999994, w1=13.52326627956579\n",
      "SubGD iter. 174/499: loss=15.388707956208911, w0=73.23329999999993, w1=13.523741235074766\n",
      "SubGD iter. 175/499: loss=15.38869465001752, w0=73.23399999999992, w1=13.523937406958076\n",
      "SubGD iter. 176/499: loss=15.388661116070383, w0=73.23455999999992, w1=13.523888604707691\n",
      "SubGD iter. 177/499: loss=15.388625559461877, w0=73.23497999999992, w1=13.524118586082972\n",
      "SubGD iter. 178/499: loss=15.388610901762975, w0=73.23539999999993, w1=13.524348567458253\n",
      "SubGD iter. 179/499: loss=15.38859647335551, w0=73.23581999999993, w1=13.524578548833533\n",
      "SubGD iter. 180/499: loss=15.388582274239473, w0=73.23623999999994, w1=13.524808530208814\n",
      "SubGD iter. 181/499: loss=15.38856830441487, w0=73.23651999999994, w1=13.524964267899264\n",
      "SubGD iter. 182/499: loss=15.388559227943112, w0=73.23679999999995, w1=13.525120005589715\n",
      "SubGD iter. 183/499: loss=15.388550254125581, w0=73.23707999999995, w1=13.525275743280165\n",
      "SubGD iter. 184/499: loss=15.388541382962282, w0=73.23721999999995, w1=13.525174424196196\n",
      "SubGD iter. 185/499: loss=15.388528823582106, w0=73.23735999999995, w1=13.525073105112227\n",
      "SubGD iter. 186/499: loss=15.388516294067486, w0=73.23749999999995, w1=13.524971786028258\n",
      "SubGD iter. 187/499: loss=15.38850379441843, w0=73.23763999999996, w1=13.52487046694429\n",
      "SubGD iter. 188/499: loss=15.38849132463492, w0=73.23777999999996, w1=13.52476914786032\n",
      "SubGD iter. 189/499: loss=15.388478884716974, w0=73.23805999999996, w1=13.52492488555077\n",
      "SubGD iter. 190/499: loss=15.3884702333119, w0=73.23819999999996, w1=13.524823566466802\n",
      "SubGD iter. 191/499: loss=15.388457846680307, w0=73.23833999999997, w1=13.524722247382833\n",
      "SubGD iter. 192/499: loss=15.388445489914275, w0=73.23847999999997, w1=13.524620928298864\n",
      "SubGD iter. 193/499: loss=15.388433163013799, w0=73.23847999999997, w1=13.524586781150308\n",
      "SubGD iter. 194/499: loss=15.388431630099818, w0=73.23847999999997, w1=13.524552634001752\n",
      "SubGD iter. 195/499: loss=15.388430098351865, w0=73.23847999999997, w1=13.524518486853196\n",
      "SubGD iter. 196/499: loss=15.388428567769942, w0=73.23847999999997, w1=13.52448433970464\n",
      "SubGD iter. 197/499: loss=15.388427038354049, w0=73.23847999999997, w1=13.524450192556085\n",
      "SubGD iter. 198/499: loss=15.388425510104181, w0=73.23847999999997, w1=13.524416045407529\n",
      "SubGD iter. 199/499: loss=15.388423983020342, w0=73.23847999999997, w1=13.524381898258973\n",
      "SubGD iter. 200/499: loss=15.388422457102529, w0=73.23861999999997, w1=13.524604807884836\n",
      "SubGD iter. 201/499: loss=15.388424687119931, w0=73.23861999999997, w1=13.52457066073628\n",
      "SubGD iter. 202/499: loss=15.388423154756419, w0=73.23861999999997, w1=13.524536513587725\n",
      "SubGD iter. 203/499: loss=15.388421623558935, w0=73.23861999999997, w1=13.524502366439169\n",
      "SubGD iter. 204/499: loss=15.388420093527477, w0=73.23861999999997, w1=13.524468219290613\n",
      "SubGD iter. 205/499: loss=15.388418564662047, w0=73.23861999999997, w1=13.524434072142057\n",
      "SubGD iter. 206/499: loss=15.388417036962647, w0=73.23861999999997, w1=13.524399924993501\n",
      "SubGD iter. 207/499: loss=15.388415510429272, w0=73.23861999999997, w1=13.524365777844945\n",
      "SubGD iter. 208/499: loss=15.388413985061927, w0=73.23861999999997, w1=13.52433163069639\n",
      "SubGD iter. 209/499: loss=15.38841246086061, w0=73.23861999999997, w1=13.524297483547834\n",
      "SubGD iter. 210/499: loss=15.388410937825316, w0=73.23875999999997, w1=13.524520393173697\n",
      "SubGD iter. 211/499: loss=15.388413168625865, w0=73.23875999999997, w1=13.524486246025141\n",
      "SubGD iter. 212/499: loss=15.388411639144877, w0=73.23875999999997, w1=13.524452098876585\n",
      "SubGD iter. 213/499: loss=15.388410110829913, w0=73.23875999999997, w1=13.52441795172803\n",
      "SubGD iter. 214/499: loss=15.388408583680977, w0=73.23875999999997, w1=13.524383804579474\n",
      "SubGD iter. 215/499: loss=15.388407057698071, w0=73.23875999999997, w1=13.524349657430918\n",
      "SubGD iter. 216/499: loss=15.38840553288119, w0=73.23875999999997, w1=13.524315510282362\n",
      "SubGD iter. 217/499: loss=15.388404009230339, w0=73.23875999999997, w1=13.524281363133806\n",
      "SubGD iter. 218/499: loss=15.388402486745516, w0=73.23875999999997, w1=13.52424721598525\n",
      "SubGD iter. 219/499: loss=15.388400965426717, w0=73.23875999999997, w1=13.524213068836694\n",
      "SubGD iter. 220/499: loss=15.388399445273949, w0=73.23889999999997, w1=13.524435978462558\n",
      "SubGD iter. 221/499: loss=15.388401676857645, w0=73.23889999999997, w1=13.524401831314002\n",
      "SubGD iter. 222/499: loss=15.38840015025918, w0=73.23889999999997, w1=13.524367684165446\n",
      "SubGD iter. 223/499: loss=15.388398624826738, w0=73.23889999999997, w1=13.52433353701689\n",
      "SubGD iter. 224/499: loss=15.388397100560324, w0=73.23889999999997, w1=13.524299389868334\n",
      "SubGD iter. 225/499: loss=15.388395577459937, w0=73.23889999999997, w1=13.524265242719778\n",
      "SubGD iter. 226/499: loss=15.38839405552558, w0=73.23889999999997, w1=13.524231095571222\n",
      "SubGD iter. 227/499: loss=15.388392534757251, w0=73.23889999999997, w1=13.524196948422667\n",
      "SubGD iter. 228/499: loss=15.388391015154944, w0=73.23889999999997, w1=13.52416280127411\n",
      "SubGD iter. 229/499: loss=15.388389496718673, w0=73.23903999999997, w1=13.524385710899974\n",
      "SubGD iter. 230/499: loss=15.388391736697248, w0=73.23903999999997, w1=13.524351563751418\n",
      "SubGD iter. 231/499: loss=15.38839021181527, w0=73.23903999999997, w1=13.524317416602862\n",
      "SubGD iter. 232/499: loss=15.388388688099322, w0=73.23903999999997, w1=13.524283269454306\n",
      "SubGD iter. 233/499: loss=15.388387165549403, w0=73.23903999999997, w1=13.52424912230575\n",
      "SubGD iter. 234/499: loss=15.388385644165513, w0=73.23903999999997, w1=13.524214975157195\n",
      "SubGD iter. 235/499: loss=15.388384123947645, w0=73.23903999999997, w1=13.524180828008639\n",
      "SubGD iter. 236/499: loss=15.388382604895812, w0=73.23903999999997, w1=13.524146680860083\n",
      "SubGD iter. 237/499: loss=15.388381087010002, w0=73.23903999999997, w1=13.524112533711527\n",
      "SubGD iter. 238/499: loss=15.388379570290219, w0=73.23903999999997, w1=13.524078386562971\n",
      "SubGD iter. 239/499: loss=15.388378054736467, w0=73.23917999999998, w1=13.524301296188835\n",
      "SubGD iter. 240/499: loss=15.388380295498191, w0=73.23917999999998, w1=13.524267149040279\n",
      "SubGD iter. 241/499: loss=15.388378773498737, w0=73.23917999999998, w1=13.524233001891723\n",
      "SubGD iter. 242/499: loss=15.388377252665311, w0=73.23917999999998, w1=13.524198854743167\n",
      "SubGD iter. 243/499: loss=15.388375732997915, w0=73.23917999999998, w1=13.524164707594611\n",
      "SubGD iter. 244/499: loss=15.388374214496546, w0=73.23917999999998, w1=13.524130560446055\n",
      "SubGD iter. 245/499: loss=15.388372697161202, w0=73.23917999999998, w1=13.5240964132975\n",
      "SubGD iter. 246/499: loss=15.388371180991887, w0=73.23917999999998, w1=13.524062266148944\n",
      "SubGD iter. 247/499: loss=15.388369665988598, w0=73.23917999999998, w1=13.524028119000388\n",
      "SubGD iter. 248/499: loss=15.388368152151342, w0=73.23917999999998, w1=13.523993971851832\n",
      "SubGD iter. 249/499: loss=15.388366639480108, w0=73.23931999999998, w1=13.524216881477695\n",
      "SubGD iter. 250/499: loss=15.388368881024979, w0=73.23931999999998, w1=13.52418273432914\n",
      "SubGD iter. 251/499: loss=15.388367361908047, w0=73.23931999999998, w1=13.524148587180584\n",
      "SubGD iter. 252/499: loss=15.388365843957144, w0=73.23931999999998, w1=13.524114440032028\n",
      "SubGD iter. 253/499: loss=15.388364327172265, w0=73.23931999999998, w1=13.524080292883472\n",
      "SubGD iter. 254/499: loss=15.388362811553417, w0=73.23931999999998, w1=13.524046145734916\n",
      "SubGD iter. 255/499: loss=15.388361297100596, w0=73.23931999999998, w1=13.52401199858636\n",
      "SubGD iter. 256/499: loss=15.388359783813806, w0=73.23931999999998, w1=13.523977851437804\n",
      "SubGD iter. 257/499: loss=15.38835827169304, w0=73.23931999999998, w1=13.523943704289248\n",
      "SubGD iter. 258/499: loss=15.3883567607383, w0=73.23931999999998, w1=13.523909557140692\n",
      "SubGD iter. 259/499: loss=15.388355250949592, w0=73.23945999999998, w1=13.524132466766556\n",
      "SubGD iter. 260/499: loss=15.38835749327761, w0=73.23945999999998, w1=13.524098319618\n",
      "SubGD iter. 261/499: loss=15.3883559770432, w0=73.23945999999998, w1=13.524064172469444\n",
      "SubGD iter. 262/499: loss=15.388354461974819, w0=73.23945999999998, w1=13.524030025320888\n",
      "SubGD iter. 263/499: loss=15.388352948072466, w0=73.23945999999998, w1=13.523995878172332\n",
      "SubGD iter. 264/499: loss=15.388351435336139, w0=73.23945999999998, w1=13.523961731023777\n",
      "SubGD iter. 265/499: loss=15.388349923765837, w0=73.23945999999998, w1=13.52392758387522\n",
      "SubGD iter. 266/499: loss=15.388348413361568, w0=73.23945999999998, w1=13.523893436726665\n",
      "SubGD iter. 267/499: loss=15.388346904123324, w0=73.23945999999998, w1=13.523859289578109\n",
      "SubGD iter. 268/499: loss=15.388345396051108, w0=73.23959999999998, w1=13.524082199203972\n",
      "SubGD iter. 269/499: loss=15.388347646774003, w0=73.23959999999998, w1=13.524048052055416\n",
      "SubGD iter. 270/499: loss=15.388346132256085, w0=73.23959999999998, w1=13.52401390490686\n",
      "SubGD iter. 271/499: loss=15.388344618904197, w0=73.23959999999998, w1=13.523979757758305\n",
      "SubGD iter. 272/499: loss=15.388343106718334, w0=73.23959999999998, w1=13.523945610609749\n",
      "SubGD iter. 273/499: loss=15.388341595698506, w0=73.23959999999998, w1=13.523911463461193\n",
      "SubGD iter. 274/499: loss=15.388340085844698, w0=73.23959999999998, w1=13.523877316312637\n",
      "SubGD iter. 275/499: loss=15.38833857715692, w0=73.23959999999998, w1=13.523843169164081\n",
      "SubGD iter. 276/499: loss=15.388337069635172, w0=73.23959999999998, w1=13.523809022015525\n",
      "SubGD iter. 277/499: loss=15.38833556327945, w0=73.23959999999998, w1=13.52377487486697\n",
      "SubGD iter. 278/499: loss=15.388334058089756, w0=73.23973999999998, w1=13.523997784492833\n",
      "SubGD iter. 279/499: loss=15.388336309595802, w0=73.23973999999998, w1=13.523963637344277\n",
      "SubGD iter. 280/499: loss=15.388334797960404, w0=73.23973999999998, w1=13.523929490195721\n",
      "SubGD iter. 281/499: loss=15.388333287491038, w0=73.23973999999998, w1=13.523895343047165\n",
      "SubGD iter. 282/499: loss=15.3883317781877, w0=73.23973999999998, w1=13.52386119589861\n",
      "SubGD iter. 283/499: loss=15.38833027005039, w0=73.23973999999998, w1=13.523827048750054\n",
      "SubGD iter. 284/499: loss=15.388328763079105, w0=73.23973999999998, w1=13.523792901601498\n",
      "SubGD iter. 285/499: loss=15.38832725727385, w0=73.23973999999998, w1=13.523758754452942\n",
      "SubGD iter. 286/499: loss=15.388325752634621, w0=73.23973999999998, w1=13.523724607304386\n",
      "SubGD iter. 287/499: loss=15.388324249161421, w0=73.23973999999998, w1=13.52369046015583\n",
      "SubGD iter. 288/499: loss=15.388322746854252, w0=73.23987999999999, w1=13.523913369781694\n",
      "SubGD iter. 289/499: loss=15.388324999143443, w0=73.23987999999999, w1=13.523879222633138\n",
      "SubGD iter. 290/499: loss=15.388323490390569, w0=73.23987999999999, w1=13.523845075484582\n",
      "SubGD iter. 291/499: loss=15.388321982803722, w0=73.23987999999999, w1=13.523810928336026\n",
      "SubGD iter. 292/499: loss=15.388320476382907, w0=73.23987999999999, w1=13.52377678118747\n",
      "SubGD iter. 293/499: loss=15.388318971128117, w0=73.23987999999999, w1=13.523742634038914\n",
      "SubGD iter. 294/499: loss=15.388317467039355, w0=73.23987999999999, w1=13.523708486890358\n",
      "SubGD iter. 295/499: loss=15.388315964116622, w0=73.23987999999999, w1=13.523674339741802\n",
      "SubGD iter. 296/499: loss=15.388314462359913, w0=73.23987999999999, w1=13.523640192593247\n",
      "SubGD iter. 297/499: loss=15.388312961769238, w0=73.23987999999999, w1=13.52360604544469\n",
      "SubGD iter. 298/499: loss=15.388311462344584, w0=73.24001999999999, w1=13.523828955070554\n",
      "SubGD iter. 299/499: loss=15.388313715416926, w0=73.24001999999999, w1=13.523794807921998\n",
      "SubGD iter. 300/499: loss=15.388312209546571, w0=73.24001999999999, w1=13.523760660773442\n",
      "SubGD iter. 301/499: loss=15.388310704842251, w0=73.24001999999999, w1=13.523726513624887\n",
      "SubGD iter. 302/499: loss=15.388309201303956, w0=73.24001999999999, w1=13.52369236647633\n",
      "SubGD iter. 303/499: loss=15.388307698931687, w0=73.24001999999999, w1=13.523658219327775\n",
      "SubGD iter. 304/499: loss=15.388306197725447, w0=73.24001999999999, w1=13.523624072179219\n",
      "SubGD iter. 305/499: loss=15.388304697685236, w0=73.24001999999999, w1=13.523589925030663\n",
      "SubGD iter. 306/499: loss=15.388303198811052, w0=73.24001999999999, w1=13.523555777882107\n",
      "SubGD iter. 307/499: loss=15.388301701102895, w0=73.24015999999999, w1=13.52377868750797\n",
      "SubGD iter. 308/499: loss=15.388303962570111, w0=73.24015999999999, w1=13.523744540359415\n",
      "SubGD iter. 309/499: loss=15.388302458416252, w0=73.24015999999999, w1=13.523710393210859\n",
      "SubGD iter. 310/499: loss=15.388300955428422, w0=73.24015999999999, w1=13.523676246062303\n",
      "SubGD iter. 311/499: loss=15.388299453606622, w0=73.24015999999999, w1=13.523642098913747\n",
      "SubGD iter. 312/499: loss=15.388297952950849, w0=73.24015999999999, w1=13.523607951765191\n",
      "SubGD iter. 313/499: loss=15.388296453461104, w0=73.24015999999999, w1=13.523573804616635\n",
      "SubGD iter. 314/499: loss=15.388294955137384, w0=73.24015999999999, w1=13.52353965746808\n",
      "SubGD iter. 315/499: loss=15.388293457979694, w0=73.24015999999999, w1=13.523505510319524\n",
      "SubGD iter. 316/499: loss=15.38829196198803, w0=73.24015999999999, w1=13.523471363170968\n",
      "SubGD iter. 317/499: loss=15.388290467162395, w0=73.24029999999999, w1=13.523694272796831\n",
      "SubGD iter. 318/499: loss=15.388292729412758, w0=73.24029999999999, w1=13.523660125648275\n",
      "SubGD iter. 319/499: loss=15.388291228141426, w0=73.24029999999999, w1=13.52362597849972\n",
      "SubGD iter. 320/499: loss=15.388289728036115, w0=73.24029999999999, w1=13.523591831351164\n",
      "SubGD iter. 321/499: loss=15.388288229096839, w0=73.24029999999999, w1=13.523557684202608\n",
      "SubGD iter. 322/499: loss=15.388286731323586, w0=73.24029999999999, w1=13.523523537054052\n",
      "SubGD iter. 323/499: loss=15.38828523471636, w0=73.24029999999999, w1=13.523489389905496\n",
      "SubGD iter. 324/499: loss=15.388283739275165, w0=73.24029999999999, w1=13.52345524275694\n",
      "SubGD iter. 325/499: loss=15.388282244999996, w0=73.24029999999999, w1=13.523421095608384\n",
      "SubGD iter. 326/499: loss=15.388280751890855, w0=73.24029999999999, w1=13.523386948459828\n",
      "SubGD iter. 327/499: loss=15.38827925994774, w0=73.24043999999999, w1=13.523609858085692\n",
      "SubGD iter. 328/499: loss=15.388281522981252, w0=73.24043999999999, w1=13.523575710937136\n",
      "SubGD iter. 329/499: loss=15.388280024592438, w0=73.24043999999999, w1=13.52354156378858\n",
      "SubGD iter. 330/499: loss=15.388278527369653, w0=73.24043999999999, w1=13.523507416640024\n",
      "SubGD iter. 331/499: loss=15.388277031312894, w0=73.24043999999999, w1=13.523473269491468\n",
      "SubGD iter. 332/499: loss=15.388275536422164, w0=73.24043999999999, w1=13.523439122342912\n",
      "SubGD iter. 333/499: loss=15.388274042697462, w0=73.24043999999999, w1=13.523404975194357\n",
      "SubGD iter. 334/499: loss=15.388272550138787, w0=73.24043999999999, w1=13.5233708280458\n",
      "SubGD iter. 335/499: loss=15.38827105874614, w0=73.24043999999999, w1=13.523336680897245\n",
      "SubGD iter. 336/499: loss=15.388269568519519, w0=73.24043999999999, w1=13.523302533748689\n",
      "SubGD iter. 337/499: loss=15.388268079458928, w0=73.24058, w1=13.523525443374552\n",
      "SubGD iter. 338/499: loss=15.38827034327559, w0=73.24058, w1=13.523491296225997\n",
      "SubGD iter. 339/499: loss=15.388268847769295, w0=73.24058, w1=13.52345714907744\n",
      "SubGD iter. 340/499: loss=15.38826735342903, w0=73.24058, w1=13.523423001928885\n",
      "SubGD iter. 341/499: loss=15.388265860254794, w0=73.24058, w1=13.523388854780329\n",
      "SubGD iter. 342/499: loss=15.388264368246588, w0=73.24058, w1=13.523354707631773\n",
      "SubGD iter. 343/499: loss=15.388262877404408, w0=73.24058, w1=13.523320560483217\n",
      "SubGD iter. 344/499: loss=15.388261387728253, w0=73.24058, w1=13.523286413334661\n",
      "SubGD iter. 345/499: loss=15.388259899218127, w0=73.24058, w1=13.523252266186105\n",
      "SubGD iter. 346/499: loss=15.388258411874029, w0=73.24058, w1=13.52321811903755\n",
      "SubGD iter. 347/499: loss=15.38825692569596, w0=73.24072, w1=13.523441028663413\n",
      "SubGD iter. 348/499: loss=15.38825919029577, w0=73.24072, w1=13.523406881514857\n",
      "SubGD iter. 349/499: loss=15.388257697671998, w0=73.24072, w1=13.523372734366301\n",
      "SubGD iter. 350/499: loss=15.388256206214256, w0=73.24072, w1=13.523338587217745\n",
      "SubGD iter. 351/499: loss=15.388254715922542, w0=73.24072, w1=13.52330444006919\n",
      "SubGD iter. 352/499: loss=15.388253226796856, w0=73.24072, w1=13.523270292920634\n",
      "SubGD iter. 353/499: loss=15.388251738837196, w0=73.24072, w1=13.523236145772078\n",
      "SubGD iter. 354/499: loss=15.388250252043564, w0=73.24072, w1=13.523201998623522\n",
      "SubGD iter. 355/499: loss=15.388248766415959, w0=73.24072, w1=13.523167851474966\n",
      "SubGD iter. 356/499: loss=15.388247281954381, w0=73.24086, w1=13.52339076110083\n",
      "SubGD iter. 357/499: loss=15.388249554949068, w0=73.24086, w1=13.523356613952274\n",
      "SubGD iter. 358/499: loss=15.388248064041793, w0=73.24086, w1=13.523322466803718\n",
      "SubGD iter. 359/499: loss=15.388246574300545, w0=73.24086, w1=13.523288319655162\n",
      "SubGD iter. 360/499: loss=15.388245085725321, w0=73.24086, w1=13.523254172506606\n",
      "SubGD iter. 361/499: loss=15.38824359831613, w0=73.24086, w1=13.52322002535805\n",
      "SubGD iter. 362/499: loss=15.388242112072964, w0=73.24086, w1=13.523185878209494\n",
      "SubGD iter. 363/499: loss=15.388240626995827, w0=73.24086, w1=13.523151731060938\n",
      "SubGD iter. 364/499: loss=15.388239143084718, w0=73.24086, w1=13.523117583912382\n",
      "SubGD iter. 365/499: loss=15.388237660339636, w0=73.24086, w1=13.523083436763827\n",
      "SubGD iter. 366/499: loss=15.38823617876058, w0=73.241, w1=13.52330634638969\n",
      "SubGD iter. 367/499: loss=15.388238452538415, w0=73.241, w1=13.523272199241134\n",
      "SubGD iter. 368/499: loss=15.38823696451366, w0=73.241, w1=13.523238052092578\n",
      "SubGD iter. 369/499: loss=15.388235477654932, w0=73.241, w1=13.523203904944022\n",
      "SubGD iter. 370/499: loss=15.388233991962231, w0=73.241, w1=13.523169757795467\n",
      "SubGD iter. 371/499: loss=15.38823250743556, w0=73.241, w1=13.52313561064691\n",
      "SubGD iter. 372/499: loss=15.388231024074917, w0=73.241, w1=13.523101463498355\n",
      "SubGD iter. 373/499: loss=15.388229541880303, w0=73.241, w1=13.523067316349799\n",
      "SubGD iter. 374/499: loss=15.388228060851711, w0=73.241, w1=13.523033169201243\n",
      "SubGD iter. 375/499: loss=15.388226580989151, w0=73.241, w1=13.522999022052687\n",
      "SubGD iter. 376/499: loss=15.38822510229262, w0=73.24114, w1=13.52322193167855\n",
      "SubGD iter. 377/499: loss=15.388227376853605, w0=73.24114, w1=13.523187784529995\n",
      "SubGD iter. 378/499: loss=15.388225891711372, w0=73.24114, w1=13.523153637381439\n",
      "SubGD iter. 379/499: loss=15.388224407735164, w0=73.24114, w1=13.523119490232883\n",
      "SubGD iter. 380/499: loss=15.388222924924985, w0=73.24114, w1=13.523085343084327\n",
      "SubGD iter. 381/499: loss=15.388221443280838, w0=73.24114, w1=13.523051195935771\n",
      "SubGD iter. 382/499: loss=15.388219962802715, w0=73.24114, w1=13.523017048787215\n",
      "SubGD iter. 383/499: loss=15.388218483490618, w0=73.24114, w1=13.52298290163866\n",
      "SubGD iter. 384/499: loss=15.388217005344556, w0=73.24114, w1=13.522948754490104\n",
      "SubGD iter. 385/499: loss=15.388215528364514, w0=73.24114, w1=13.522914607341548\n",
      "SubGD iter. 386/499: loss=15.388214052550504, w0=73.24128, w1=13.523137516967411\n",
      "SubGD iter. 387/499: loss=15.388216327894636, w0=73.24128, w1=13.523103369818855\n",
      "SubGD iter. 388/499: loss=15.388214845634923, w0=73.24128, w1=13.5230692226703\n",
      "SubGD iter. 389/499: loss=15.38821336454124, w0=73.24128, w1=13.523035075521744\n",
      "SubGD iter. 390/499: loss=15.388211884613586, w0=73.24128, w1=13.523000928373188\n",
      "SubGD iter. 391/499: loss=15.388210405851956, w0=73.24128, w1=13.522966781224632\n",
      "SubGD iter. 392/499: loss=15.388208928256354, w0=73.24128, w1=13.522932634076076\n",
      "SubGD iter. 393/499: loss=15.388207451826782, w0=73.24128, w1=13.52289848692752\n",
      "SubGD iter. 394/499: loss=15.388205976563238, w0=73.24128, w1=13.522864339778964\n",
      "SubGD iter. 395/499: loss=15.388204502465719, w0=73.24142, w1=13.523087249404828\n",
      "SubGD iter. 396/499: loss=15.388206786204728, w0=73.24142, w1=13.523053102256272\n",
      "SubGD iter. 397/499: loss=15.388205305661511, w0=73.24142, w1=13.523018955107716\n",
      "SubGD iter. 398/499: loss=15.388203826284322, w0=73.24142, w1=13.52298480795916\n",
      "SubGD iter. 399/499: loss=15.38820234807316, w0=73.24142, w1=13.522950660810604\n",
      "SubGD iter. 400/499: loss=15.388200871028024, w0=73.24142, w1=13.522916513662048\n",
      "SubGD iter. 401/499: loss=15.388199395148918, w0=73.24142, w1=13.522882366513493\n",
      "SubGD iter. 402/499: loss=15.38819792043584, w0=73.24142, w1=13.522848219364937\n",
      "SubGD iter. 403/499: loss=15.38819644688879, w0=73.24142, w1=13.52281407221638\n",
      "SubGD iter. 404/499: loss=15.388194974507764, w0=73.24142, w1=13.522779925067825\n",
      "SubGD iter. 405/499: loss=15.388193503292769, w0=73.24156, w1=13.523002834693688\n",
      "SubGD iter. 406/499: loss=15.388195787814926, w0=73.24156, w1=13.522968687545132\n",
      "SubGD iter. 407/499: loss=15.38819431015423, w0=73.24156, w1=13.522934540396577\n",
      "SubGD iter. 408/499: loss=15.388192833659563, w0=73.24156, w1=13.52290039324802\n",
      "SubGD iter. 409/499: loss=15.388191358330918, w0=73.24156, w1=13.522866246099465\n",
      "SubGD iter. 410/499: loss=15.388189884168309, w0=73.24156, w1=13.522832098950909\n",
      "SubGD iter. 411/499: loss=15.388188411171726, w0=73.24156, w1=13.522797951802353\n",
      "SubGD iter. 412/499: loss=15.388186939341168, w0=73.24156, w1=13.522763804653797\n",
      "SubGD iter. 413/499: loss=15.388185468676634, w0=73.24156, w1=13.522729657505241\n",
      "SubGD iter. 414/499: loss=15.388183999178137, w0=73.24156, w1=13.522695510356685\n",
      "SubGD iter. 415/499: loss=15.388182530845661, w0=73.24170000000001, w1=13.522918419982549\n",
      "SubGD iter. 416/499: loss=15.388184816150966, w0=73.24156, w1=13.522905630681082\n",
      "SubGD iter. 417/499: loss=15.388191584538678, w0=73.24156, w1=13.522871483532526\n",
      "SubGD iter. 418/499: loss=15.38819011019722, w0=73.24156, w1=13.52283733638397\n",
      "SubGD iter. 419/499: loss=15.388188637021793, w0=73.24156, w1=13.522803189235415\n",
      "SubGD iter. 420/499: loss=15.388187165012392, w0=73.24156, w1=13.522769042086859\n",
      "SubGD iter. 421/499: loss=15.388185694169021, w0=73.24156, w1=13.522734894938303\n",
      "SubGD iter. 422/499: loss=15.388184224491674, w0=73.24156, w1=13.522700747789747\n",
      "SubGD iter. 423/499: loss=15.388182755980356, w0=73.24170000000001, w1=13.52292365741561\n",
      "SubGD iter. 424/499: loss=15.388185042453136, w0=73.24156, w1=13.522910868114144\n",
      "SubGD iter. 425/499: loss=15.388191810773863, w0=73.24156, w1=13.522876720965588\n",
      "SubGD iter. 426/499: loss=15.388190336253563, w0=73.24156, w1=13.522842573817032\n",
      "SubGD iter. 427/499: loss=15.388188862899293, w0=73.24156, w1=13.522808426668476\n",
      "SubGD iter. 428/499: loss=15.388187390711048, w0=73.24156, w1=13.52277427951992\n",
      "SubGD iter. 429/499: loss=15.388185919688834, w0=73.24156, w1=13.522740132371364\n",
      "SubGD iter. 430/499: loss=15.388184449832645, w0=73.24156, w1=13.522705985222808\n",
      "SubGD iter. 431/499: loss=15.388182981142483, w0=73.24170000000001, w1=13.522928894848672\n",
      "SubGD iter. 432/499: loss=15.388185268782737, w0=73.24156, w1=13.522916105547205\n",
      "SubGD iter. 433/499: loss=15.388192037036479, w0=73.24156, w1=13.52288195839865\n",
      "SubGD iter. 434/499: loss=15.388190562337337, w0=73.24156, w1=13.522847811250093\n",
      "SubGD iter. 435/499: loss=15.388189088804223, w0=73.24156, w1=13.522813664101538\n",
      "SubGD iter. 436/499: loss=15.388187616437138, w0=73.24156, w1=13.522779516952982\n",
      "SubGD iter. 437/499: loss=15.388186145236078, w0=73.24156, w1=13.522745369804426\n",
      "SubGD iter. 438/499: loss=15.388184675201046, w0=73.24156, w1=13.52271122265587\n",
      "SubGD iter. 439/499: loss=15.388183206332041, w0=73.24170000000001, w1=13.522934132281733\n",
      "SubGD iter. 440/499: loss=15.38818549513977, w0=73.24156, w1=13.522921342980267\n",
      "SubGD iter. 441/499: loss=15.388192263326529, w0=73.24156, w1=13.52288719583171\n",
      "SubGD iter. 442/499: loss=15.38819078844854, w0=73.24156, w1=13.522853048683155\n",
      "SubGD iter. 443/499: loss=15.388189314736582, w0=73.24156, w1=13.522818901534599\n",
      "SubGD iter. 444/499: loss=15.388187842190653, w0=73.24156, w1=13.522784754386043\n",
      "SubGD iter. 445/499: loss=15.38818637081075, w0=73.24156, w1=13.522750607237487\n",
      "SubGD iter. 446/499: loss=15.388184900596874, w0=73.24156, w1=13.522716460088931\n",
      "SubGD iter. 447/499: loss=15.388183431549027, w0=73.24170000000001, w1=13.522939369714795\n",
      "SubGD iter. 448/499: loss=15.388185721524229, w0=73.24156, w1=13.522926580413328\n",
      "SubGD iter. 449/499: loss=15.388192489644005, w0=73.24156, w1=13.522892433264772\n",
      "SubGD iter. 450/499: loss=15.388191014587175, w0=73.24156, w1=13.522858286116216\n",
      "SubGD iter. 451/499: loss=15.388189540696377, w0=73.24156, w1=13.52282413896766\n",
      "SubGD iter. 452/499: loss=15.388188067971601, w0=73.24156, w1=13.522789991819105\n",
      "SubGD iter. 453/499: loss=15.388186596412854, w0=73.24156, w1=13.522755844670549\n",
      "SubGD iter. 454/499: loss=15.388185126020137, w0=73.24156, w1=13.522721697521993\n",
      "SubGD iter. 455/499: loss=15.388183656793446, w0=73.24156, w1=13.522687550373437\n",
      "SubGD iter. 456/499: loss=15.388182188732783, w0=73.24170000000001, w1=13.5229104599993\n",
      "SubGD iter. 457/499: loss=15.38818447226373, w0=73.24156, w1=13.522897670697834\n",
      "SubGD iter. 458/499: loss=15.388191240753246, w0=73.24156, w1=13.522863523549278\n",
      "SubGD iter. 459/499: loss=15.388189766683599, w0=73.24156, w1=13.522829376400722\n",
      "SubGD iter. 460/499: loss=15.38818829377998, w0=73.24156, w1=13.522795229252166\n",
      "SubGD iter. 461/499: loss=15.388186822042393, w0=73.24156, w1=13.52276108210361\n",
      "SubGD iter. 462/499: loss=15.38818535147083, w0=73.24156, w1=13.522726934955054\n",
      "SubGD iter. 463/499: loss=15.388183882065295, w0=73.24156, w1=13.522692787806498\n",
      "SubGD iter. 464/499: loss=15.388182413825788, w0=73.24170000000001, w1=13.522915697432362\n",
      "SubGD iter. 465/499: loss=15.38818469852421, w0=73.24156, w1=13.522902908130895\n",
      "SubGD iter. 466/499: loss=15.38819146694674, w0=73.24156, w1=13.52286876098234\n",
      "SubGD iter. 467/499: loss=15.388189992698253, w0=73.24156, w1=13.522834613833783\n",
      "SubGD iter. 468/499: loss=15.38818851961579, w0=73.24156, w1=13.522800466685228\n",
      "SubGD iter. 469/499: loss=15.388187047699356, w0=73.24156, w1=13.522766319536672\n",
      "SubGD iter. 470/499: loss=15.38818557694895, w0=73.24156, w1=13.522732172388116\n",
      "SubGD iter. 471/499: loss=15.388184107364575, w0=73.24156, w1=13.52269802523956\n",
      "SubGD iter. 472/499: loss=15.388182638946223, w0=73.24170000000001, w1=13.522920934865423\n",
      "SubGD iter. 473/499: loss=15.388184924812121, w0=73.24156, w1=13.522908145563957\n",
      "SubGD iter. 474/499: loss=15.388191693167668, w0=73.24156, w1=13.5228739984154\n",
      "SubGD iter. 475/499: loss=15.388190218740338, w0=73.24156, w1=13.522839851266845\n",
      "SubGD iter. 476/499: loss=15.38818874547903, w0=73.24156, w1=13.522805704118289\n",
      "SubGD iter. 477/499: loss=15.388187273383755, w0=73.24156, w1=13.522771556969733\n",
      "SubGD iter. 478/499: loss=15.388185802454506, w0=73.24156, w1=13.522737409821177\n",
      "SubGD iter. 479/499: loss=15.388184332691285, w0=73.24156, w1=13.522703262672621\n",
      "SubGD iter. 480/499: loss=15.38818286409409, w0=73.24170000000001, w1=13.522926172298485\n",
      "SubGD iter. 481/499: loss=15.38818515112746, w0=73.24156, w1=13.522913382997018\n",
      "SubGD iter. 482/499: loss=15.388191919416023, w0=73.24156, w1=13.522879235848462\n",
      "SubGD iter. 483/499: loss=15.388190444809851, w0=73.24156, w1=13.522845088699906\n",
      "SubGD iter. 484/499: loss=15.388188971369702, w0=73.24156, w1=13.52281094155135\n",
      "SubGD iter. 485/499: loss=15.388187499095581, w0=73.24156, w1=13.522776794402795\n",
      "SubGD iter. 486/499: loss=15.388186027987487, w0=73.24156, w1=13.522742647254239\n",
      "SubGD iter. 487/499: loss=15.388184558045424, w0=73.24156, w1=13.522708500105683\n",
      "SubGD iter. 488/499: loss=15.38818308926939, w0=73.24170000000001, w1=13.522931409731546\n",
      "SubGD iter. 489/499: loss=15.388185377470235, w0=73.24156, w1=13.52291862043008\n",
      "SubGD iter. 490/499: loss=15.388192145691812, w0=73.24156, w1=13.522884473281524\n",
      "SubGD iter. 491/499: loss=15.388190670906797, w0=73.24156, w1=13.522850326132968\n",
      "SubGD iter. 492/499: loss=15.388189197287804, w0=73.24156, w1=13.522816178984412\n",
      "SubGD iter. 493/499: loss=15.388187724834841, w0=73.24156, w1=13.522782031835856\n",
      "SubGD iter. 494/499: loss=15.388186253547904, w0=73.24156, w1=13.5227478846873\n",
      "SubGD iter. 495/499: loss=15.388184783426999, w0=73.24156, w1=13.522713737538744\n",
      "SubGD iter. 496/499: loss=15.388183314472117, w0=73.24170000000001, w1=13.522936647164608\n",
      "SubGD iter. 497/499: loss=15.388185603840437, w0=73.24156, w1=13.522923857863141\n",
      "SubGD iter. 498/499: loss=15.388192371995034, w0=73.24156, w1=13.522889710714585\n",
      "SubGD iter. 499/499: loss=15.388190897031173, w0=73.24156, w1=13.52285556356603\n",
      "SubGD: execution time=0.068 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(\n",
    "    y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cbaad708164f5a9719816478211491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses, subgd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic SubGradient Descent algorithm (SubSGD).\n",
    "            \n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        \n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    \n",
    "    for n_iter in range(max_iters):\n",
    "\n",
    "        # implement stochastic subgradient descent.\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size, num_batches=1, shuffle=True):\n",
    "            grad = compute_subgradient_mae(minibatch_y, minibatch_tx, w)\n",
    "            loss = compute_loss(minibatch_y, minibatch_tx, w)\n",
    "            w = w - gamma * grad\n",
    "            \n",
    "            ws.append(w)\n",
    "            losses.append(loss)\n",
    "        \n",
    "        \n",
    "        print(\"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=2529.824541739742, w0=0.7, w1=-0.025192728467127137\n",
      "SubSGD iter. 1/499: loss=4376.569954153675, w0=1.4, w1=0.8192062744993879\n",
      "SubSGD iter. 2/499: loss=1581.2869118636434, w0=2.0999999999999996, w1=0.2427425014125022\n",
      "SubSGD iter. 3/499: loss=4315.576059833873, w0=2.8, w1=1.694824709721522\n",
      "SubSGD iter. 4/499: loss=1827.1887378783715, w0=3.5, w1=1.193322532330269\n",
      "SubSGD iter. 5/499: loss=2073.5027941023673, w0=4.2, w1=0.6865428746724538\n",
      "SubSGD iter. 6/499: loss=1867.7378190362629, w0=4.9, w1=0.8736652803722518\n",
      "SubSGD iter. 7/499: loss=1777.0810368132277, w0=5.6000000000000005, w1=0.4285602141635165\n",
      "SubSGD iter. 8/499: loss=1928.0002977355177, w0=6.300000000000001, w1=0.11553237333346933\n",
      "SubSGD iter. 9/499: loss=1469.7262611609278, w0=7.000000000000001, w1=-0.14853231969466635\n",
      "SubSGD iter. 10/499: loss=3225.967503218692, w0=7.700000000000001, w1=0.6544554121229751\n",
      "SubSGD iter. 11/499: loss=2090.4551990706004, w0=8.4, w1=0.48934872731544954\n",
      "SubSGD iter. 12/499: loss=682.0875379540024, w0=9.1, w1=-0.8963931592435459\n",
      "SubSGD iter. 13/499: loss=4153.515380647441, w0=9.799999999999999, w1=0.25156512505853446\n",
      "SubSGD iter. 14/499: loss=2711.4790846957085, w0=10.499999999999998, w1=0.6814151240798113\n",
      "SubSGD iter. 15/499: loss=1029.0308384438533, w0=11.199999999999998, w1=0.041165263229612004\n",
      "SubSGD iter. 16/499: loss=1085.0289063613764, w0=11.899999999999997, w1=-0.3763308237992148\n",
      "SubSGD iter. 17/499: loss=3495.68073315379, w0=12.599999999999996, w1=0.5307785508082241\n",
      "SubSGD iter. 18/499: loss=2876.9205328358894, w0=13.299999999999995, w1=1.4195495404395388\n",
      "SubSGD iter. 19/499: loss=3224.2348938203663, w0=13.999999999999995, w1=1.8439224631928122\n",
      "SubSGD iter. 20/499: loss=1779.7974754314089, w0=14.699999999999994, w1=1.4057098919363717\n",
      "SubSGD iter. 21/499: loss=837.8414128585686, w0=15.399999999999993, w1=0.8722560271570626\n",
      "SubSGD iter. 22/499: loss=1901.5477301082844, w0=16.099999999999994, w1=1.0816978573798128\n",
      "SubSGD iter. 23/499: loss=1118.5005862255243, w0=16.799999999999994, w1=0.5994503637372174\n",
      "SubSGD iter. 24/499: loss=2639.7372310435417, w0=17.499999999999993, w1=1.723579695268644\n",
      "SubSGD iter. 25/499: loss=1584.31597432048, w0=18.199999999999992, w1=1.3812281103424824\n",
      "SubSGD iter. 26/499: loss=702.9880162650518, w0=18.89999999999999, w1=0.7164212571421579\n",
      "SubSGD iter. 27/499: loss=1715.833376430036, w0=19.59999999999999, w1=1.003988066333427\n",
      "SubSGD iter. 28/499: loss=855.8968905819787, w0=20.29999999999999, w1=0.3230603739637109\n",
      "SubSGD iter. 29/499: loss=1497.2444280066811, w0=20.99999999999999, w1=0.10810464606564169\n",
      "SubSGD iter. 30/499: loss=351.028400425019, w0=21.69999999999999, w1=-0.7858005662964433\n",
      "SubSGD iter. 31/499: loss=2184.855181124754, w0=22.399999999999988, w1=0.18729287442569054\n",
      "SubSGD iter. 32/499: loss=1819.6320692770785, w0=23.099999999999987, w1=0.4330690666111068\n",
      "SubSGD iter. 33/499: loss=1816.359328036554, w0=23.799999999999986, w1=0.8571107765464739\n",
      "SubSGD iter. 34/499: loss=1328.0295641562082, w0=24.499999999999986, w1=1.3315174653355064\n",
      "SubSGD iter. 35/499: loss=2600.968908894355, w0=25.199999999999985, w1=2.664826969996184\n",
      "SubSGD iter. 36/499: loss=2367.2712981089926, w0=25.899999999999984, w1=3.800687390433395\n",
      "SubSGD iter. 37/499: loss=1282.2329536040156, w0=26.599999999999984, w1=3.845599449516961\n",
      "SubSGD iter. 38/499: loss=1370.3172241281281, w0=27.299999999999983, w1=4.428110821472735\n",
      "SubSGD iter. 39/499: loss=672.474684123205, w0=27.999999999999982, w1=3.897351163920123\n",
      "SubSGD iter. 40/499: loss=273.1182514521404, w0=28.69999999999998, w1=2.7721868463771098\n",
      "SubSGD iter. 41/499: loss=1131.4499423994928, w0=29.39999999999998, w1=3.6681446503158806\n",
      "SubSGD iter. 42/499: loss=1889.1747647720308, w0=30.09999999999998, w1=4.628952291628632\n",
      "SubSGD iter. 43/499: loss=1056.672304608717, w0=30.79999999999998, w1=5.021184730476896\n",
      "SubSGD iter. 44/499: loss=459.1207464771842, w0=31.49999999999998, w1=4.334657006269521\n",
      "SubSGD iter. 45/499: loss=383.7166255612455, w0=32.19999999999998, w1=3.2825036738064615\n",
      "SubSGD iter. 46/499: loss=562.5764234885397, w0=32.899999999999984, w1=2.868240149841606\n",
      "SubSGD iter. 47/499: loss=1006.0052031852373, w0=33.59999999999999, w1=3.0284717328238595\n",
      "SubSGD iter. 48/499: loss=352.3248793891718, w0=34.29999999999999, w1=2.7047056189713485\n",
      "SubSGD iter. 49/499: loss=729.7930497247372, w0=34.99999999999999, w1=2.432975641314183\n",
      "SubSGD iter. 50/499: loss=185.78133526538133, w0=35.699999999999996, w1=1.5974068221064028\n",
      "SubSGD iter. 51/499: loss=814.9841097709573, w0=36.4, w1=1.6475664693120613\n",
      "SubSGD iter. 52/499: loss=1204.4049044295236, w0=37.1, w1=2.2680531857842303\n",
      "SubSGD iter. 53/499: loss=655.5273791656181, w0=37.800000000000004, w1=2.457285083801702\n",
      "SubSGD iter. 54/499: loss=350.85139362865675, w0=38.50000000000001, w1=1.9420029744235054\n",
      "SubSGD iter. 55/499: loss=621.5720962664706, w0=39.20000000000001, w1=1.9769792969090347\n",
      "SubSGD iter. 56/499: loss=524.022281719108, w0=39.90000000000001, w1=1.5449238221086055\n",
      "SubSGD iter. 57/499: loss=173.999844230184, w0=40.600000000000016, w1=0.8475768888652858\n",
      "SubSGD iter. 58/499: loss=177.7886496245475, w0=41.30000000000002, w1=0.2059039562300885\n",
      "SubSGD iter. 59/499: loss=1242.2324273554086, w0=42.00000000000002, w1=0.8143937774833833\n",
      "SubSGD iter. 60/499: loss=650.4180301217783, w0=42.700000000000024, w1=1.1895328686240814\n",
      "SubSGD iter. 61/499: loss=1020.8203045528408, w0=43.40000000000003, w1=2.023468116244475\n",
      "SubSGD iter. 62/499: loss=50.69190388969314, w0=44.10000000000003, w1=1.2636946470177643\n",
      "SubSGD iter. 63/499: loss=437.6702853692697, w0=44.80000000000003, w1=1.636101373524365\n",
      "SubSGD iter. 64/499: loss=1007.3559086973632, w0=45.500000000000036, w1=1.6557517169516325\n",
      "SubSGD iter. 65/499: loss=734.5565240048994, w0=46.20000000000004, w1=1.9969773200524037\n",
      "SubSGD iter. 66/499: loss=1551.8552750963202, w0=46.90000000000004, w1=3.693925134232879\n",
      "SubSGD iter. 67/499: loss=535.3948380376828, w0=47.600000000000044, w1=4.304829266684411\n",
      "SubSGD iter. 68/499: loss=294.29404793738894, w0=48.30000000000005, w1=4.61686090576923\n",
      "SubSGD iter. 69/499: loss=131.5683504668374, w0=49.00000000000005, w1=4.328090214841755\n",
      "SubSGD iter. 70/499: loss=491.0127630166572, w0=49.70000000000005, w1=4.976668318666494\n",
      "SubSGD iter. 71/499: loss=145.06823571971154, w0=50.400000000000055, w1=4.557192790799677\n",
      "SubSGD iter. 72/499: loss=30.853507147732483, w0=51.10000000000006, w1=4.634160991122114\n",
      "SubSGD iter. 73/499: loss=746.0646011801919, w0=51.80000000000006, w1=5.6769977949410695\n",
      "SubSGD iter. 74/499: loss=164.58273495482197, w0=52.500000000000064, w1=5.033526986276834\n",
      "SubSGD iter. 75/499: loss=71.25412582567233, w0=53.20000000000007, w1=4.000383042054544\n",
      "SubSGD iter. 76/499: loss=133.00109858380586, w0=53.90000000000007, w1=4.00032876173896\n",
      "SubSGD iter. 77/499: loss=379.02315485477, w0=54.60000000000007, w1=4.520601763703725\n",
      "SubSGD iter. 78/499: loss=10.385443201600557, w0=55.300000000000075, w1=3.462498039041428\n",
      "SubSGD iter. 79/499: loss=734.3343587083245, w0=56.00000000000008, w1=4.746468367511937\n",
      "SubSGD iter. 80/499: loss=51.970376863131996, w0=56.70000000000008, w1=5.001909731363101\n",
      "SubSGD iter. 81/499: loss=112.48007268248621, w0=57.400000000000084, w1=5.146418077356078\n",
      "SubSGD iter. 82/499: loss=856.292348262631, w0=58.10000000000009, w1=7.093182589120312\n",
      "SubSGD iter. 83/499: loss=65.30834501227758, w0=58.80000000000009, w1=7.267149261338876\n",
      "SubSGD iter. 84/499: loss=170.4257570041225, w0=59.50000000000009, w1=7.756034850887216\n",
      "SubSGD iter. 85/499: loss=259.0396433442891, w0=60.200000000000095, w1=8.213009212382213\n",
      "SubSGD iter. 86/499: loss=197.62001577555347, w0=60.9000000000001, w1=8.987944201234148\n",
      "SubSGD iter. 87/499: loss=49.18699103597413, w0=61.6000000000001, w1=8.617366856191875\n",
      "SubSGD iter. 88/499: loss=234.59015416717452, w0=62.300000000000104, w1=8.822537619029797\n",
      "SubSGD iter. 89/499: loss=38.746731525870565, w0=63.00000000000011, w1=7.878619269583274\n",
      "SubSGD iter. 90/499: loss=14.107933197622744, w0=63.70000000000011, w1=6.939559214590351\n",
      "SubSGD iter. 91/499: loss=7.131329203053356, w0=64.4000000000001, w1=7.04338495522895\n",
      "SubSGD iter. 92/499: loss=103.32497294771696, w0=65.10000000000011, w1=7.17438326796203\n",
      "SubSGD iter. 93/499: loss=5.67635122631777, w0=64.4000000000001, w1=7.667279792954866\n",
      "SubSGD iter. 94/499: loss=226.738360387536, w0=65.10000000000011, w1=8.179865366873992\n",
      "SubSGD iter. 95/499: loss=0.0004194361252967285, w0=64.4000000000001, w1=8.51843922829247\n",
      "SubSGD iter. 96/499: loss=17.464982917526562, w0=65.10000000000011, w1=8.354323339863319\n",
      "SubSGD iter. 97/499: loss=0.1812949610516088, w0=65.80000000000011, w1=7.809775653135382\n",
      "SubSGD iter. 98/499: loss=0.7201811812378048, w0=65.10000000000011, w1=8.965936106409941\n",
      "SubSGD iter. 99/499: loss=14.285917475179154, w0=64.4000000000001, w1=10.463893342738011\n",
      "SubSGD iter. 100/499: loss=26.862123101770983, w0=65.10000000000011, w1=9.923576235781312\n",
      "SubSGD iter. 101/499: loss=28.0577429963862, w0=64.4000000000001, w1=10.685590652312156\n",
      "SubSGD iter. 102/499: loss=32.4094307669381, w0=65.10000000000011, w1=11.071103301867078\n",
      "SubSGD iter. 103/499: loss=175.52914595363418, w0=65.80000000000011, w1=11.700616759289115\n",
      "SubSGD iter. 104/499: loss=23.97283926734311, w0=66.50000000000011, w1=11.278979790109231\n",
      "SubSGD iter. 105/499: loss=16.014805860845485, w0=67.20000000000012, w1=11.843630105053746\n",
      "SubSGD iter. 106/499: loss=68.09325469191064, w0=67.90000000000012, w1=12.309006488202797\n",
      "SubSGD iter. 107/499: loss=0.2555959222044488, w0=67.20000000000012, w1=12.782167489738239\n",
      "SubSGD iter. 108/499: loss=30.45535605237146, w0=67.90000000000012, w1=13.656054387138024\n",
      "SubSGD iter. 109/499: loss=92.14103031635614, w0=68.60000000000012, w1=14.020539909056838\n",
      "SubSGD iter. 110/499: loss=23.678906336061313, w0=69.30000000000013, w1=13.54781210415394\n",
      "SubSGD iter. 111/499: loss=60.070406055450896, w0=70.00000000000013, w1=14.297960602901973\n",
      "SubSGD iter. 112/499: loss=57.01871608020056, w0=70.70000000000013, w1=14.909691283772915\n",
      "SubSGD iter. 113/499: loss=83.92175163868163, w0=71.40000000000013, w1=14.168657597217706\n",
      "SubSGD iter. 114/499: loss=18.853013377969532, w0=72.10000000000014, w1=14.70771913892576\n",
      "SubSGD iter. 115/499: loss=0.9737323170085284, w0=71.40000000000013, w1=14.573049721523542\n",
      "SubSGD iter. 116/499: loss=6.72531366233179, w0=70.70000000000013, w1=14.420796720335458\n",
      "SubSGD iter. 117/499: loss=0.2473482924099577, w0=70.00000000000013, w1=15.068971804226933\n",
      "SubSGD iter. 118/499: loss=15.740061266717273, w0=69.30000000000013, w1=15.337012904169063\n",
      "SubSGD iter. 119/499: loss=0.05992558265618981, w0=70.00000000000013, w1=16.142804248596192\n",
      "SubSGD iter. 120/499: loss=22.791365524063774, w0=69.30000000000013, w1=15.86477556959634\n",
      "SubSGD iter. 121/499: loss=49.1254325792963, w0=70.00000000000013, w1=16.429145588306096\n",
      "SubSGD iter. 122/499: loss=6.7359219891179976, w0=69.30000000000013, w1=16.91534610664668\n",
      "SubSGD iter. 123/499: loss=110.2963044770363, w0=70.00000000000013, w1=17.10538421196535\n",
      "SubSGD iter. 124/499: loss=1.5022122936395192, w0=69.30000000000013, w1=16.34454497879586\n",
      "SubSGD iter. 125/499: loss=3.293481610764841, w0=70.00000000000013, w1=16.131907570212626\n",
      "SubSGD iter. 126/499: loss=0.741131606263383, w0=69.30000000000013, w1=16.60176772777807\n",
      "SubSGD iter. 127/499: loss=0.2543301878858657, w0=70.00000000000013, w1=17.338161232572507\n",
      "SubSGD iter. 128/499: loss=9.508048923270467, w0=70.70000000000013, w1=16.71925331586622\n",
      "SubSGD iter. 129/499: loss=20.86071093970057, w0=70.00000000000013, w1=15.90202761200536\n",
      "SubSGD iter. 130/499: loss=40.9902016192588, w0=70.70000000000013, w1=15.617217617934417\n",
      "SubSGD iter. 131/499: loss=11.563064917137146, w0=71.40000000000013, w1=16.057444902130257\n",
      "SubSGD iter. 132/499: loss=1.3909298801008019, w0=70.70000000000013, w1=15.107128312188081\n",
      "SubSGD iter. 133/499: loss=35.9589799785149, w0=70.00000000000013, w1=14.916905071226202\n",
      "SubSGD iter. 134/499: loss=22.999077574159703, w0=70.70000000000013, w1=14.159079579942045\n",
      "SubSGD iter. 135/499: loss=10.856319200061764, w0=71.40000000000013, w1=15.560025740718352\n",
      "SubSGD iter. 136/499: loss=3.3597821638475085, w0=72.10000000000014, w1=14.489536926713193\n",
      "SubSGD iter. 137/499: loss=13.474688740416571, w0=71.40000000000013, w1=15.390570089187824\n",
      "SubSGD iter. 138/499: loss=1.0115674412883011, w0=72.10000000000014, w1=16.207541730760497\n",
      "SubSGD iter. 139/499: loss=7.35848687257831, w0=71.40000000000013, w1=16.79748149120063\n",
      "SubSGD iter. 140/499: loss=10.366239064333415, w0=72.10000000000014, w1=15.835116945380463\n",
      "SubSGD iter. 141/499: loss=5.363282138965733, w0=71.40000000000013, w1=16.00956091922663\n",
      "SubSGD iter. 142/499: loss=63.37922922522071, w0=72.10000000000014, w1=16.130411370349705\n",
      "SubSGD iter. 143/499: loss=6.019332128628442, w0=71.40000000000013, w1=15.248646118430944\n",
      "SubSGD iter. 144/499: loss=32.6156025443005, w0=72.10000000000014, w1=15.487190156220397\n",
      "SubSGD iter. 145/499: loss=0.8644512338339853, w0=72.80000000000014, w1=16.0617680552388\n",
      "SubSGD iter. 146/499: loss=3.713944285437326, w0=72.10000000000014, w1=16.3683585242772\n",
      "SubSGD iter. 147/499: loss=43.99508552455441, w0=72.80000000000014, w1=15.369609374162717\n",
      "SubSGD iter. 148/499: loss=132.66735161553672, w0=72.10000000000014, w1=14.587842816601148\n",
      "SubSGD iter. 149/499: loss=4.818394049182471, w0=71.40000000000013, w1=14.813879094576627\n",
      "SubSGD iter. 150/499: loss=0.2997399935000473, w0=70.70000000000013, w1=14.46305110676787\n",
      "SubSGD iter. 151/499: loss=7.674939516341257, w0=71.40000000000013, w1=14.261072309824186\n",
      "SubSGD iter. 152/499: loss=5.451312801731234, w0=72.10000000000014, w1=12.867154181499691\n",
      "SubSGD iter. 153/499: loss=2.392781193113465, w0=71.40000000000013, w1=13.145413313458407\n",
      "SubSGD iter. 154/499: loss=8.51147311180422, w0=70.70000000000013, w1=13.504725335527086\n",
      "SubSGD iter. 155/499: loss=40.97497948952729, w0=70.00000000000013, w1=12.227109184866107\n",
      "SubSGD iter. 156/499: loss=18.339222357345292, w0=70.70000000000013, w1=11.9243964963752\n",
      "SubSGD iter. 157/499: loss=9.508462565663809, w0=70.00000000000013, w1=11.948497759378254\n",
      "SubSGD iter. 158/499: loss=3.8420382836023235, w0=70.70000000000013, w1=12.917590356566578\n",
      "SubSGD iter. 159/499: loss=30.106243443017558, w0=71.40000000000013, w1=13.318799726858169\n",
      "SubSGD iter. 160/499: loss=8.036476602343047, w0=70.70000000000013, w1=13.855099057525964\n",
      "SubSGD iter. 161/499: loss=4.812537848148055, w0=71.40000000000013, w1=13.937920637332024\n",
      "SubSGD iter. 162/499: loss=29.82955424553479, w0=72.10000000000014, w1=14.314911796746788\n",
      "SubSGD iter. 163/499: loss=55.887594403150054, w0=71.40000000000013, w1=15.413051312067138\n",
      "SubSGD iter. 164/499: loss=26.445798852273576, w0=72.10000000000014, w1=14.270918201337368\n",
      "SubSGD iter. 165/499: loss=3.0595651223072076, w0=72.80000000000014, w1=14.568044951704108\n",
      "SubSGD iter. 166/499: loss=4.636989704927702, w0=73.50000000000014, w1=14.819427475248496\n",
      "SubSGD iter. 167/499: loss=3.1779220803245174, w0=74.20000000000014, w1=13.784680134726523\n",
      "SubSGD iter. 168/499: loss=0.6811497213567804, w0=74.90000000000015, w1=12.728263116064568\n",
      "SubSGD iter. 169/499: loss=1.0545284065959173, w0=74.20000000000014, w1=13.78483917133386\n",
      "SubSGD iter. 170/499: loss=0.07942274951450363, w0=73.50000000000014, w1=13.866952491936452\n",
      "SubSGD iter. 171/499: loss=0.3738854293415656, w0=72.80000000000014, w1=13.352721791336927\n",
      "SubSGD iter. 172/499: loss=5.257071518400569, w0=72.10000000000014, w1=13.167843288481617\n",
      "SubSGD iter. 173/499: loss=14.87937131687607, w0=71.40000000000013, w1=13.936978230221857\n",
      "SubSGD iter. 174/499: loss=3.90493324292775, w0=72.10000000000014, w1=12.90295654808848\n",
      "SubSGD iter. 175/499: loss=15.527653592260272, w0=72.80000000000014, w1=13.443734553267111\n",
      "SubSGD iter. 176/499: loss=69.86319416958025, w0=73.50000000000014, w1=13.141061692123627\n",
      "SubSGD iter. 177/499: loss=8.153890208255714, w0=72.80000000000014, w1=13.878312099919993\n",
      "SubSGD iter. 178/499: loss=8.429348811499775, w0=73.50000000000014, w1=12.695190024424015\n",
      "SubSGD iter. 179/499: loss=27.81791620445538, w0=72.80000000000014, w1=11.116563896299517\n",
      "SubSGD iter. 180/499: loss=6.983082795844826, w0=73.50000000000014, w1=11.20659582706655\n",
      "SubSGD iter. 181/499: loss=3.320941676741149, w0=72.80000000000014, w1=11.318129762466139\n",
      "SubSGD iter. 182/499: loss=2.708247214457333, w0=72.10000000000014, w1=11.759814866553759\n",
      "SubSGD iter. 183/499: loss=3.7334436333759524, w0=71.40000000000013, w1=12.24980436800814\n",
      "SubSGD iter. 184/499: loss=5.7843004364762844, w0=72.10000000000014, w1=13.992264836404178\n",
      "SubSGD iter. 185/499: loss=10.3524789468047, w0=72.80000000000014, w1=14.376848992029014\n",
      "SubSGD iter. 186/499: loss=4.321171440437656, w0=72.10000000000014, w1=14.65631685834414\n",
      "SubSGD iter. 187/499: loss=35.822461770544415, w0=72.80000000000014, w1=14.754799121306535\n",
      "SubSGD iter. 188/499: loss=2.3868324661322173, w0=73.50000000000014, w1=13.81058634533016\n",
      "SubSGD iter. 189/499: loss=86.40428702717895, w0=72.80000000000014, w1=13.534985697735376\n",
      "SubSGD iter. 190/499: loss=0.24327301053745798, w0=73.50000000000014, w1=12.969649561206213\n",
      "SubSGD iter. 191/499: loss=0.2672147118723488, w0=74.20000000000014, w1=13.79570792161396\n",
      "SubSGD iter. 192/499: loss=0.0011724684834934773, w0=74.90000000000015, w1=13.7106362959694\n",
      "SubSGD iter. 193/499: loss=2.224335782105071, w0=75.60000000000015, w1=13.81593485190074\n",
      "SubSGD iter. 194/499: loss=5.181000377064303, w0=76.30000000000015, w1=13.252664836831482\n",
      "SubSGD iter. 195/499: loss=26.813161284945036, w0=75.60000000000015, w1=13.76829825247249\n",
      "SubSGD iter. 196/499: loss=0.14558823837171253, w0=76.30000000000015, w1=14.643362507456862\n",
      "SubSGD iter. 197/499: loss=41.39103696322803, w0=75.60000000000015, w1=14.649771417277082\n",
      "SubSGD iter. 198/499: loss=0.38651194386595183, w0=74.90000000000015, w1=14.671598915943518\n",
      "SubSGD iter. 199/499: loss=3.2811738054774424, w0=74.20000000000014, w1=15.612311097287195\n",
      "SubSGD iter. 200/499: loss=114.18939523780503, w0=73.50000000000014, w1=14.923187260422358\n",
      "SubSGD iter. 201/499: loss=2.456211058256957, w0=74.20000000000014, w1=14.010288608095614\n",
      "SubSGD iter. 202/499: loss=0.13601417428167834, w0=74.90000000000015, w1=14.056717031937982\n",
      "SubSGD iter. 203/499: loss=51.315222604267284, w0=74.20000000000014, w1=14.202293302187291\n",
      "SubSGD iter. 204/499: loss=0.0010706988128652258, w0=73.50000000000014, w1=14.157184059713233\n",
      "SubSGD iter. 205/499: loss=6.439763664476874, w0=74.20000000000014, w1=14.383210263733195\n",
      "SubSGD iter. 206/499: loss=3.6022460676554737, w0=74.90000000000015, w1=14.28689078369168\n",
      "SubSGD iter. 207/499: loss=51.83593809618271, w0=74.20000000000014, w1=13.263343583932112\n",
      "SubSGD iter. 208/499: loss=6.147874877157177, w0=73.50000000000014, w1=13.83376384757846\n",
      "SubSGD iter. 209/499: loss=0.49844054772541313, w0=72.80000000000014, w1=14.43575014114213\n",
      "SubSGD iter. 210/499: loss=100.39120351249568, w0=72.10000000000014, w1=14.515567379043189\n",
      "SubSGD iter. 211/499: loss=10.468770802795394, w0=72.80000000000014, w1=14.995670097081668\n",
      "SubSGD iter. 212/499: loss=0.7526604055126322, w0=73.50000000000014, w1=16.073149610500263\n",
      "SubSGD iter. 213/499: loss=21.327826412565887, w0=72.80000000000014, w1=16.514352403270863\n",
      "SubSGD iter. 214/499: loss=55.67612558663507, w0=72.10000000000014, w1=15.23648131368509\n",
      "SubSGD iter. 215/499: loss=18.91698903969296, w0=71.40000000000013, w1=14.19808713595355\n",
      "SubSGD iter. 216/499: loss=0.13886016596186493, w0=70.70000000000013, w1=14.838004606327921\n",
      "SubSGD iter. 217/499: loss=2.953311780042057, w0=71.40000000000013, w1=14.438631082360045\n",
      "SubSGD iter. 218/499: loss=19.78282473567179, w0=72.10000000000014, w1=14.64049286296502\n",
      "SubSGD iter. 219/499: loss=8.720698669870727, w0=72.80000000000014, w1=14.172618653446982\n",
      "SubSGD iter. 220/499: loss=12.557766372392454, w0=72.10000000000014, w1=14.302241426102752\n",
      "SubSGD iter. 221/499: loss=5.091775782322955, w0=71.40000000000013, w1=14.100012040203158\n",
      "SubSGD iter. 222/499: loss=0.3870527208005491, w0=70.70000000000013, w1=13.666145219930296\n",
      "SubSGD iter. 223/499: loss=1.2673314222262566, w0=71.40000000000013, w1=12.973290291418701\n",
      "SubSGD iter. 224/499: loss=42.029237980382426, w0=72.10000000000014, w1=13.530712298896843\n",
      "SubSGD iter. 225/499: loss=0.11178031670212794, w0=71.40000000000013, w1=13.360440706520667\n",
      "SubSGD iter. 226/499: loss=0.4432169120389555, w0=70.70000000000013, w1=13.130360029968731\n",
      "SubSGD iter. 227/499: loss=61.225949681915104, w0=71.40000000000013, w1=13.10982833726451\n",
      "SubSGD iter. 228/499: loss=0.22804421522726662, w0=72.10000000000014, w1=12.800101755135564\n",
      "SubSGD iter. 229/499: loss=0.03232804772425883, w0=71.40000000000013, w1=12.088240641293574\n",
      "SubSGD iter. 230/499: loss=0.011547989591699481, w0=72.10000000000014, w1=12.516363944521034\n",
      "SubSGD iter. 231/499: loss=72.91054285232892, w0=71.40000000000013, w1=12.506105227286424\n",
      "SubSGD iter. 232/499: loss=4.268467112883964, w0=72.10000000000014, w1=13.242498732080861\n",
      "SubSGD iter. 233/499: loss=1.9881454016637914, w0=71.40000000000013, w1=12.04081194307657\n",
      "SubSGD iter. 234/499: loss=20.88968859765143, w0=72.10000000000014, w1=12.408577300364898\n",
      "SubSGD iter. 235/499: loss=18.277181719832342, w0=72.80000000000014, w1=13.451414104183854\n",
      "SubSGD iter. 236/499: loss=18.34006201733928, w0=72.10000000000014, w1=14.344562135391966\n",
      "SubSGD iter. 237/499: loss=20.161021002808482, w0=72.80000000000014, w1=14.822059443832718\n",
      "SubSGD iter. 238/499: loss=7.329128583547719, w0=72.10000000000014, w1=13.888160810254753\n",
      "SubSGD iter. 239/499: loss=5.263607863576711, w0=72.80000000000014, w1=13.022745803364694\n",
      "SubSGD iter. 240/499: loss=19.21029815935462, w0=73.50000000000014, w1=12.989367931075924\n",
      "SubSGD iter. 241/499: loss=14.58815778601052, w0=72.80000000000014, w1=13.61765191105605\n",
      "SubSGD iter. 242/499: loss=84.32509957757469, w0=73.50000000000014, w1=13.046939195254893\n",
      "SubSGD iter. 243/499: loss=9.22014195562135, w0=74.20000000000014, w1=12.976238757887167\n",
      "SubSGD iter. 244/499: loss=26.162323327057365, w0=74.90000000000015, w1=12.676042808882569\n",
      "SubSGD iter. 245/499: loss=10.188032870703704, w0=74.20000000000014, w1=11.722473839236253\n",
      "SubSGD iter. 246/499: loss=85.38859385919294, w0=73.50000000000014, w1=12.384222805857622\n",
      "SubSGD iter. 247/499: loss=0.0248286057229924, w0=74.20000000000014, w1=12.872450582155592\n",
      "SubSGD iter. 248/499: loss=14.991679124207716, w0=73.50000000000014, w1=12.141001357952002\n",
      "SubSGD iter. 249/499: loss=30.34913797711749, w0=74.20000000000014, w1=11.668456755530224\n",
      "SubSGD iter. 250/499: loss=9.816059672390463, w0=74.90000000000015, w1=11.874000923663035\n",
      "SubSGD iter. 251/499: loss=7.767360963505747, w0=74.20000000000014, w1=12.79488939697046\n",
      "SubSGD iter. 252/499: loss=2.059807985282814, w0=73.50000000000014, w1=12.054890165483195\n",
      "SubSGD iter. 253/499: loss=67.29059655976317, w0=74.20000000000014, w1=11.813793747651447\n",
      "SubSGD iter. 254/499: loss=11.305258176509737, w0=74.90000000000015, w1=10.896966930506016\n",
      "SubSGD iter. 255/499: loss=0.011986595077261903, w0=75.60000000000015, w1=11.132195765379096\n",
      "SubSGD iter. 256/499: loss=34.115329410391155, w0=74.90000000000015, w1=11.494799850698573\n",
      "SubSGD iter. 257/499: loss=1.574106139900745, w0=74.20000000000014, w1=10.911874556385065\n",
      "SubSGD iter. 258/499: loss=16.030487779532905, w0=73.50000000000014, w1=10.353428116249187\n",
      "SubSGD iter. 259/499: loss=0.23900295526374332, w0=72.80000000000014, w1=9.862802995320333\n",
      "SubSGD iter. 260/499: loss=42.65300608667434, w0=73.50000000000014, w1=10.492284124532322\n",
      "SubSGD iter. 261/499: loss=5.5546093231930636, w0=74.20000000000014, w1=10.243721825254896\n",
      "SubSGD iter. 262/499: loss=26.268839368423002, w0=73.50000000000014, w1=11.344941051073933\n",
      "SubSGD iter. 263/499: loss=0.35100268986410316, w0=74.20000000000014, w1=11.390050293547992\n",
      "SubSGD iter. 264/499: loss=7.39405796935974, w0=73.50000000000014, w1=12.122002639441874\n",
      "SubSGD iter. 265/499: loss=12.152161959451227, w0=72.80000000000014, w1=11.452058566270185\n",
      "SubSGD iter. 266/499: loss=0.052413102588742426, w0=73.50000000000014, w1=10.798380327313065\n",
      "SubSGD iter. 267/499: loss=4.916904306055933, w0=72.80000000000014, w1=11.564411411430957\n",
      "SubSGD iter. 268/499: loss=1.5333073588328863, w0=72.10000000000014, w1=11.334330734879021\n",
      "SubSGD iter. 269/499: loss=25.301862355512874, w0=72.80000000000014, w1=11.963839897900938\n",
      "SubSGD iter. 270/499: loss=0.7660208914701765, w0=73.50000000000014, w1=12.099934914134435\n",
      "SubSGD iter. 271/499: loss=28.478731512547856, w0=72.80000000000014, w1=11.509826815343773\n",
      "SubSGD iter. 272/499: loss=3.2245791205318675, w0=72.10000000000014, w1=11.376411364779166\n",
      "SubSGD iter. 273/499: loss=0.744941344616625, w0=72.80000000000014, w1=10.731218328468252\n",
      "SubSGD iter. 274/499: loss=0.5969286617516864, w0=72.10000000000014, w1=11.087931240426236\n",
      "SubSGD iter. 275/499: loss=7.949288277384412, w0=71.40000000000013, w1=11.98698145584241\n",
      "SubSGD iter. 276/499: loss=27.13637312266963, w0=70.70000000000013, w1=13.125764102517746\n",
      "SubSGD iter. 277/499: loss=0.5327664378526306, w0=71.40000000000013, w1=11.804237925883381\n",
      "SubSGD iter. 278/499: loss=4.534284917551938, w0=70.70000000000013, w1=11.965574888730309\n",
      "SubSGD iter. 279/499: loss=0.7609386066470073, w0=71.40000000000013, w1=11.487766328661944\n",
      "SubSGD iter. 280/499: loss=3.297866875714897, w0=72.10000000000014, w1=10.02783321787683\n",
      "SubSGD iter. 281/499: loss=28.557850073287455, w0=71.40000000000013, w1=10.38595941030247\n",
      "SubSGD iter. 282/499: loss=1.898231145392223, w0=72.10000000000014, w1=10.021822744111079\n",
      "SubSGD iter. 283/499: loss=12.702756144529959, w0=71.40000000000013, w1=10.53783375278472\n",
      "SubSGD iter. 284/499: loss=140.01116259171752, w0=72.10000000000014, w1=11.946944234171882\n",
      "SubSGD iter. 285/499: loss=0.1315954304284689, w0=72.80000000000014, w1=12.080853524700716\n",
      "SubSGD iter. 286/499: loss=46.67762209366741, w0=72.10000000000014, w1=13.204428505834782\n",
      "SubSGD iter. 287/499: loss=2.229842811468316, w0=72.80000000000014, w1=13.274324838992626\n",
      "SubSGD iter. 288/499: loss=9.007604774370215, w0=73.50000000000014, w1=13.585534334157693\n",
      "SubSGD iter. 289/499: loss=0.822910495631832, w0=74.20000000000014, w1=12.561092833206459\n",
      "SubSGD iter. 290/499: loss=20.815173411756295, w0=74.90000000000015, w1=13.317191477817918\n",
      "SubSGD iter. 291/499: loss=1.6654960499617384, w0=75.60000000000015, w1=12.666189033631369\n",
      "SubSGD iter. 292/499: loss=0.13030985197048356, w0=74.90000000000015, w1=12.238132189288994\n",
      "SubSGD iter. 293/499: loss=3.811065276994448, w0=74.20000000000014, w1=11.973670356326645\n",
      "SubSGD iter. 294/499: loss=5.301204880265225, w0=74.90000000000015, w1=12.198127751337545\n",
      "SubSGD iter. 295/499: loss=15.414309248832708, w0=74.20000000000014, w1=11.336315362387824\n",
      "SubSGD iter. 296/499: loss=24.048912546886307, w0=73.50000000000014, w1=11.289558562531319\n",
      "SubSGD iter. 297/499: loss=0.2665046403530278, w0=74.20000000000014, w1=11.898408783969966\n",
      "SubSGD iter. 298/499: loss=37.21861427299019, w0=73.50000000000014, w1=12.01613124699288\n",
      "SubSGD iter. 299/499: loss=20.39489749829684, w0=74.20000000000014, w1=13.692179204042178\n",
      "SubSGD iter. 300/499: loss=6.235578976136822, w0=74.90000000000015, w1=14.298800582169898\n",
      "SubSGD iter. 301/499: loss=1.0595926728006237, w0=74.20000000000014, w1=13.066016939223935\n",
      "SubSGD iter. 302/499: loss=6.4761781501603615, w0=73.50000000000014, w1=13.392272649252556\n",
      "SubSGD iter. 303/499: loss=2.6476924101017216, w0=74.20000000000014, w1=13.633143047907632\n",
      "SubSGD iter. 304/499: loss=22.403852644733846, w0=74.90000000000015, w1=14.608985373119753\n",
      "SubSGD iter. 305/499: loss=0.597103914491709, w0=75.60000000000015, w1=15.866838932313906\n",
      "SubSGD iter. 306/499: loss=1.2516966401613074, w0=74.90000000000015, w1=15.818235976721828\n",
      "SubSGD iter. 307/499: loss=0.10814248033807747, w0=75.60000000000015, w1=16.047816078291106\n",
      "SubSGD iter. 308/499: loss=17.601733231615547, w0=74.90000000000015, w1=15.46529012105114\n",
      "SubSGD iter. 309/499: loss=51.23031259813537, w0=74.20000000000014, w1=16.19845253378449\n",
      "SubSGD iter. 310/499: loss=33.600366742677444, w0=73.50000000000014, w1=15.27023545708146\n",
      "SubSGD iter. 311/499: loss=20.376904728847464, w0=72.80000000000014, w1=15.481054973866684\n",
      "SubSGD iter. 312/499: loss=1.2383989339552957, w0=73.50000000000014, w1=14.901263365515296\n",
      "SubSGD iter. 313/499: loss=13.748378187576929, w0=72.80000000000014, w1=15.50288787460485\n",
      "SubSGD iter. 314/499: loss=1.8532438668042814, w0=73.50000000000014, w1=15.568526139967148\n",
      "SubSGD iter. 315/499: loss=31.524621854535148, w0=72.80000000000014, w1=15.909419678184353\n",
      "SubSGD iter. 316/499: loss=2.7464453705366676, w0=72.10000000000014, w1=15.524581045540204\n",
      "SubSGD iter. 317/499: loss=9.932232843382257, w0=72.80000000000014, w1=14.654524625781557\n",
      "SubSGD iter. 318/499: loss=54.97299422024837, w0=73.50000000000014, w1=15.037019195079722\n",
      "SubSGD iter. 319/499: loss=48.247743611958725, w0=72.80000000000014, w1=14.543004651607728\n",
      "SubSGD iter. 320/499: loss=42.83694940994901, w0=73.50000000000014, w1=13.685432089267291\n",
      "SubSGD iter. 321/499: loss=5.249304043518352, w0=74.20000000000014, w1=14.04693119842015\n",
      "SubSGD iter. 322/499: loss=28.41581316032957, w0=73.50000000000014, w1=14.870834062545901\n",
      "SubSGD iter. 323/499: loss=4.538753088751157, w0=72.80000000000014, w1=14.036720640663754\n",
      "SubSGD iter. 324/499: loss=18.17967137454501, w0=73.50000000000014, w1=14.456979584771583\n",
      "SubSGD iter. 325/499: loss=0.02562713689070384, w0=72.80000000000014, w1=14.254268880816413\n",
      "SubSGD iter. 326/499: loss=23.635936437225045, w0=73.50000000000014, w1=13.166413177439068\n",
      "SubSGD iter. 327/499: loss=22.97355361843513, w0=72.80000000000014, w1=13.535337816411703\n",
      "SubSGD iter. 328/499: loss=30.234048693835717, w0=72.10000000000014, w1=13.281353952508056\n",
      "SubSGD iter. 329/499: loss=1.1528039629703468, w0=71.40000000000013, w1=13.983675273216358\n",
      "SubSGD iter. 330/499: loss=57.11423043185264, w0=72.10000000000014, w1=13.23720785999599\n",
      "SubSGD iter. 331/499: loss=109.96092489359994, w0=72.80000000000014, w1=13.248521455415775\n",
      "SubSGD iter. 332/499: loss=0.09113592386708012, w0=73.50000000000014, w1=14.11333693369928\n",
      "SubSGD iter. 333/499: loss=4.149637326154461, w0=74.20000000000014, w1=14.071095276677518\n",
      "SubSGD iter. 334/499: loss=15.419529818802927, w0=74.90000000000015, w1=14.56391111528642\n",
      "SubSGD iter. 335/499: loss=33.73923847720309, w0=74.20000000000014, w1=14.979407405446782\n",
      "SubSGD iter. 336/499: loss=50.66937286704465, w0=74.90000000000015, w1=14.74065014403236\n",
      "SubSGD iter. 337/499: loss=16.569437838817567, w0=74.20000000000014, w1=15.075688523398899\n",
      "SubSGD iter. 338/499: loss=20.088089085986642, w0=73.50000000000014, w1=13.693471349597612\n",
      "SubSGD iter. 339/499: loss=32.52253159004664, w0=74.20000000000014, w1=13.885957295375038\n",
      "SubSGD iter. 340/499: loss=2.7217655172101956, w0=74.90000000000015, w1=13.290685079569128\n",
      "SubSGD iter. 341/499: loss=17.9305696930733, w0=74.20000000000014, w1=12.503951952868121\n",
      "SubSGD iter. 342/499: loss=4.933009955840554, w0=74.90000000000015, w1=13.03922109069104\n",
      "SubSGD iter. 343/499: loss=0.02536003911386295, w0=74.20000000000014, w1=12.421462903272705\n",
      "SubSGD iter. 344/499: loss=0.09729166105363851, w0=74.90000000000015, w1=12.11885326812764\n",
      "SubSGD iter. 345/499: loss=0.047737026498498626, w0=75.60000000000015, w1=10.393734238821486\n",
      "SubSGD iter. 346/499: loss=75.48703014096614, w0=74.90000000000015, w1=9.958510098376921\n",
      "SubSGD iter. 347/499: loss=2.8853486962611314, w0=74.20000000000014, w1=9.579182284650852\n",
      "SubSGD iter. 348/499: loss=13.078744476696953, w0=73.50000000000014, w1=10.096741302437268\n",
      "SubSGD iter. 349/499: loss=46.28741134192641, w0=72.80000000000014, w1=10.329278149814465\n",
      "SubSGD iter. 350/499: loss=31.886718695061827, w0=72.10000000000014, w1=11.71502003637346\n",
      "SubSGD iter. 351/499: loss=46.65165748763575, w0=72.80000000000014, w1=12.254782293262366\n",
      "SubSGD iter. 352/499: loss=2.3685510057531345, w0=72.10000000000014, w1=12.567209670786651\n",
      "SubSGD iter. 353/499: loss=17.237663470842207, w0=71.40000000000013, w1=12.502822260931874\n",
      "SubSGD iter. 354/499: loss=5.938902341083901, w0=72.10000000000014, w1=13.739408924296564\n",
      "SubSGD iter. 355/499: loss=78.1425011688975, w0=72.80000000000014, w1=13.201106982542312\n",
      "SubSGD iter. 356/499: loss=17.38119113950253, w0=72.10000000000014, w1=13.512162194824255\n",
      "SubSGD iter. 357/499: loss=18.429669573384672, w0=72.80000000000014, w1=14.270326587613518\n",
      "SubSGD iter. 358/499: loss=3.6272167035966945, w0=72.10000000000014, w1=14.472639428551744\n",
      "SubSGD iter. 359/499: loss=22.39428602128588, w0=71.40000000000013, w1=13.952906048844453\n",
      "SubSGD iter. 360/499: loss=5.115054222100921, w0=70.70000000000013, w1=12.732407489209336\n",
      "SubSGD iter. 361/499: loss=79.33723272865367, w0=71.40000000000013, w1=13.53795818999563\n",
      "SubSGD iter. 362/499: loss=9.13022917380097, w0=70.70000000000013, w1=12.682939863647201\n",
      "SubSGD iter. 363/499: loss=5.163673224251428, w0=71.40000000000013, w1=11.559125535147272\n",
      "SubSGD iter. 364/499: loss=1.5354061504546561, w0=72.10000000000014, w1=10.496864579295035\n",
      "SubSGD iter. 365/499: loss=5.38284251574353, w0=71.40000000000013, w1=11.157713013612621\n",
      "SubSGD iter. 366/499: loss=18.02226372136316, w0=70.70000000000013, w1=11.988316121286516\n",
      "SubSGD iter. 367/499: loss=2.3863333646496647, w0=71.40000000000013, w1=13.217247752576794\n",
      "SubSGD iter. 368/499: loss=21.62570650740793, w0=72.10000000000014, w1=12.639269345023132\n",
      "SubSGD iter. 369/499: loss=38.62469287300149, w0=72.80000000000014, w1=12.487006924651226\n",
      "SubSGD iter. 370/499: loss=14.275516474418449, w0=73.50000000000014, w1=12.870890173494276\n",
      "SubSGD iter. 371/499: loss=63.08442596492461, w0=74.20000000000014, w1=12.801643741065266\n",
      "SubSGD iter. 372/499: loss=8.750969972040599, w0=73.50000000000014, w1=14.545054824461172\n",
      "SubSGD iter. 373/499: loss=96.06392976996129, w0=74.20000000000014, w1=13.625006987254835\n",
      "SubSGD iter. 374/499: loss=5.794107799878722, w0=74.90000000000015, w1=13.685611099014935\n",
      "SubSGD iter. 375/499: loss=0.38526570474707816, w0=74.20000000000014, w1=12.910676110163\n",
      "SubSGD iter. 376/499: loss=0.6764865930700981, w0=74.90000000000015, w1=12.638369788098801\n",
      "SubSGD iter. 377/499: loss=23.16063990036219, w0=75.60000000000015, w1=11.956517107633946\n",
      "SubSGD iter. 378/499: loss=9.698264830219184, w0=74.90000000000015, w1=11.926996980072945\n",
      "SubSGD iter. 379/499: loss=5.315988638451653, w0=74.20000000000014, w1=13.10135306494694\n",
      "SubSGD iter. 380/499: loss=27.450302559673144, w0=74.90000000000015, w1=12.850366718050523\n",
      "SubSGD iter. 381/499: loss=0.8791524614406181, w0=75.60000000000015, w1=13.239841039682737\n",
      "SubSGD iter. 382/499: loss=37.00588177968246, w0=74.90000000000015, w1=13.406948205059713\n",
      "SubSGD iter. 383/499: loss=27.660967949633292, w0=75.60000000000015, w1=13.663873377185988\n",
      "SubSGD iter. 384/499: loss=16.2009247696131, w0=74.90000000000015, w1=12.10142755266331\n",
      "SubSGD iter. 385/499: loss=41.25135784147816, w0=74.20000000000014, w1=12.93699637187109\n",
      "SubSGD iter. 386/499: loss=1.9113015904532311, w0=73.50000000000014, w1=11.952417643670474\n",
      "SubSGD iter. 387/499: loss=5.526623194584483, w0=72.80000000000014, w1=12.649403801059037\n",
      "SubSGD iter. 388/499: loss=0.9090456135777414, w0=72.10000000000014, w1=12.122517541091618\n",
      "SubSGD iter. 389/499: loss=0.7294292069300901, w0=71.40000000000013, w1=11.38631548144665\n",
      "SubSGD iter. 390/499: loss=3.903566590814581, w0=72.10000000000014, w1=11.63582645168242\n",
      "SubSGD iter. 391/499: loss=1.8518265447316913, w0=71.40000000000013, w1=10.818600747821561\n",
      "SubSGD iter. 392/499: loss=34.4529209807984, w0=72.10000000000014, w1=11.400034476795073\n",
      "SubSGD iter. 393/499: loss=0.0008931838735247875, w0=71.40000000000013, w1=11.070417663285184\n",
      "SubSGD iter. 394/499: loss=5.296365482827209, w0=70.70000000000013, w1=10.336288098347106\n",
      "SubSGD iter. 395/499: loss=0.26588993698331803, w0=71.40000000000013, w1=10.82915205003387\n",
      "SubSGD iter. 396/499: loss=13.879372479374105, w0=70.70000000000013, w1=11.01657397773623\n",
      "SubSGD iter. 397/499: loss=11.26720043941344, w0=71.40000000000013, w1=10.18587545293706\n",
      "SubSGD iter. 398/499: loss=33.991182626933536, w0=72.10000000000014, w1=10.443313480484358\n",
      "SubSGD iter. 399/499: loss=3.7049490531896674, w0=71.40000000000013, w1=10.911997398587996\n",
      "SubSGD iter. 400/499: loss=3.4525452236245164, w0=70.70000000000013, w1=11.313807332583025\n",
      "SubSGD iter. 401/499: loss=0.24066773045795278, w0=71.40000000000013, w1=12.185045467636229\n",
      "SubSGD iter. 402/499: loss=2.966275054442911, w0=70.70000000000013, w1=12.966222557521712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 403/499: loss=17.625407734701874, w0=71.40000000000013, w1=13.710807885523014\n",
      "SubSGD iter. 404/499: loss=11.35496256129199, w0=72.10000000000014, w1=14.638032255118231\n",
      "SubSGD iter. 405/499: loss=0.025588874566683475, w0=72.80000000000014, w1=15.44477220471463\n",
      "SubSGD iter. 406/499: loss=57.05070338383378, w0=72.10000000000014, w1=14.586497522308795\n",
      "SubSGD iter. 407/499: loss=59.96940879017675, w0=71.40000000000013, w1=13.690539718370024\n",
      "SubSGD iter. 408/499: loss=4.884350495823276, w0=72.10000000000014, w1=14.632150080540717\n",
      "SubSGD iter. 409/499: loss=5.060519476342407, w0=72.80000000000014, w1=15.379946030155233\n",
      "SubSGD iter. 410/499: loss=91.48759433669036, w0=72.10000000000014, w1=14.433175504135491\n",
      "SubSGD iter. 411/499: loss=26.681967337211294, w0=72.80000000000014, w1=14.564840964380034\n",
      "SubSGD iter. 412/499: loss=30.765340668186163, w0=73.50000000000014, w1=15.07742653829916\n",
      "SubSGD iter. 413/499: loss=7.993026193282632, w0=74.20000000000014, w1=15.323202730484578\n",
      "SubSGD iter. 414/499: loss=3.164836096772587, w0=73.50000000000014, w1=15.937148713894054\n",
      "SubSGD iter. 415/499: loss=1.5740595464079423, w0=72.80000000000014, w1=15.392790518764278\n",
      "SubSGD iter. 416/499: loss=8.801840097646357, w0=73.50000000000014, w1=15.144316147502236\n",
      "SubSGD iter. 417/499: loss=0.9317254004941631, w0=72.80000000000014, w1=15.607272388033964\n",
      "SubSGD iter. 418/499: loss=13.952954272817578, w0=73.50000000000014, w1=16.21076235264093\n",
      "SubSGD iter. 419/499: loss=0.7899855299957714, w0=72.80000000000014, w1=17.144374293280862\n",
      "SubSGD iter. 420/499: loss=4.306491438272079, w0=73.50000000000014, w1=16.45151936476927\n",
      "SubSGD iter. 421/499: loss=2.5464549898807927, w0=74.20000000000014, w1=17.130112214441457\n",
      "SubSGD iter. 422/499: loss=13.372919928522197, w0=73.50000000000014, w1=16.46832207739112\n",
      "SubSGD iter. 423/499: loss=5.315857395555206, w0=72.80000000000014, w1=17.502288650835347\n",
      "SubSGD iter. 424/499: loss=2.0255673202429536, w0=73.50000000000014, w1=17.731868752404626\n",
      "SubSGD iter. 425/499: loss=1.647264544726557, w0=72.80000000000014, w1=16.779548505764524\n",
      "SubSGD iter. 426/499: loss=58.05954229482783, w0=73.50000000000014, w1=15.666911616095708\n",
      "SubSGD iter. 427/499: loss=7.325430011785459, w0=72.80000000000014, w1=16.684980748872412\n",
      "SubSGD iter. 428/499: loss=50.005733377343496, w0=73.50000000000014, w1=15.792263580343747\n",
      "SubSGD iter. 429/499: loss=8.223696109043905, w0=72.80000000000014, w1=14.849746085868183\n",
      "SubSGD iter. 430/499: loss=56.64994664479266, w0=72.10000000000014, w1=14.813511460079033\n",
      "SubSGD iter. 431/499: loss=14.26760444264276, w0=71.40000000000013, w1=14.651001057559773\n",
      "SubSGD iter. 432/499: loss=12.14564365714976, w0=72.10000000000014, w1=14.951687047974595\n",
      "SubSGD iter. 433/499: loss=48.02709274072816, w0=71.40000000000013, w1=14.61424988130802\n",
      "SubSGD iter. 434/499: loss=6.875160231243592, w0=72.10000000000014, w1=14.413608406994282\n",
      "SubSGD iter. 435/499: loss=0.09098187642754593, w0=72.80000000000014, w1=14.528110007067996\n",
      "SubSGD iter. 436/499: loss=2.951731227561611, w0=72.10000000000014, w1=14.414835115315206\n",
      "SubSGD iter. 437/499: loss=31.238409327607407, w0=72.80000000000014, w1=13.782208234743836\n",
      "SubSGD iter. 438/499: loss=9.1318284537428, w0=72.10000000000014, w1=13.505135505050074\n",
      "SubSGD iter. 439/499: loss=0.3580655190247289, w0=72.80000000000014, w1=14.06428502496185\n",
      "SubSGD iter. 440/499: loss=1.1414191917601932, w0=72.10000000000014, w1=14.794164030004275\n",
      "SubSGD iter. 441/499: loss=8.177244691694597, w0=71.40000000000013, w1=14.922376613177128\n",
      "SubSGD iter. 442/499: loss=0.06146440910025732, w0=72.10000000000014, w1=14.511128489612453\n",
      "SubSGD iter. 443/499: loss=2.602280543965427, w0=71.40000000000013, w1=15.691743338339055\n",
      "SubSGD iter. 444/499: loss=2.776077376120334, w0=70.70000000000013, w1=15.46836893190762\n",
      "SubSGD iter. 445/499: loss=5.993390236883683, w0=71.40000000000013, w1=14.689654553528742\n",
      "SubSGD iter. 446/499: loss=31.1902135466212, w0=72.10000000000014, w1=14.374549209252239\n",
      "SubSGD iter. 447/499: loss=0.1924940167499143, w0=72.80000000000014, w1=14.431803923532245\n",
      "SubSGD iter. 448/499: loss=0.032928310549024654, w0=73.50000000000014, w1=13.985337689803963\n",
      "SubSGD iter. 449/499: loss=8.804405668615114, w0=74.20000000000014, w1=14.206139002860732\n",
      "SubSGD iter. 450/499: loss=9.450968591229833, w0=73.50000000000014, w1=15.003525432875918\n",
      "SubSGD iter. 451/499: loss=0.0832510486779317, w0=72.80000000000014, w1=14.234226164430435\n",
      "SubSGD iter. 452/499: loss=22.1190804993694, w0=72.10000000000014, w1=13.39710726481646\n",
      "SubSGD iter. 453/499: loss=10.64071495935522, w0=72.80000000000014, w1=13.733279909250435\n",
      "SubSGD iter. 454/499: loss=7.348640108550345, w0=73.50000000000014, w1=13.211053786875045\n",
      "SubSGD iter. 455/499: loss=33.24296944400398, w0=72.80000000000014, w1=12.4731667865423\n",
      "SubSGD iter. 456/499: loss=3.426947826556985, w0=73.50000000000014, w1=11.440022842320012\n",
      "SubSGD iter. 457/499: loss=15.181465127202188, w0=74.20000000000014, w1=12.022086284163425\n",
      "SubSGD iter. 458/499: loss=11.69926421701018, w0=74.90000000000015, w1=11.905364109296345\n",
      "SubSGD iter. 459/499: loss=43.39539308108515, w0=74.20000000000014, w1=12.744926950537476\n",
      "SubSGD iter. 460/499: loss=9.815125315091354, w0=74.90000000000015, w1=13.495230305334328\n",
      "SubSGD iter. 461/499: loss=25.52204586617524, w0=74.20000000000014, w1=14.350192295571174\n",
      "SubSGD iter. 462/499: loss=12.866735191118824, w0=74.90000000000015, w1=13.564107479846435\n",
      "SubSGD iter. 463/499: loss=0.620193923439513, w0=75.60000000000015, w1=14.144000069993428\n",
      "SubSGD iter. 464/499: loss=18.709800819369267, w0=76.30000000000015, w1=14.139011054430926\n",
      "SubSGD iter. 465/499: loss=92.13175125737737, w0=75.60000000000015, w1=13.562841235829996\n",
      "SubSGD iter. 466/499: loss=7.033618703023291, w0=74.90000000000015, w1=13.48488242617373\n",
      "SubSGD iter. 467/499: loss=56.13564636020232, w0=74.20000000000014, w1=13.206853747173877\n",
      "SubSGD iter. 468/499: loss=0.10021854823512111, w0=73.50000000000014, w1=12.322943491027242\n",
      "SubSGD iter. 469/499: loss=12.644332870955482, w0=72.80000000000014, w1=12.498097040424758\n",
      "SubSGD iter. 470/499: loss=21.33630248592728, w0=72.10000000000014, w1=11.985150916939164\n",
      "SubSGD iter. 471/499: loss=44.02011721481591, w0=72.80000000000014, w1=12.100465345408889\n",
      "SubSGD iter. 472/499: loss=7.023682768967208, w0=73.50000000000014, w1=11.95348989650877\n",
      "SubSGD iter. 473/499: loss=0.00154559450851564, w0=74.20000000000014, w1=12.070998998825363\n",
      "SubSGD iter. 474/499: loss=28.894433900223234, w0=74.90000000000015, w1=12.43435501593761\n",
      "SubSGD iter. 475/499: loss=21.311676648161818, w0=74.20000000000014, w1=12.383962593603309\n",
      "SubSGD iter. 476/499: loss=63.57537393332544, w0=73.50000000000014, w1=12.516975144285635\n",
      "SubSGD iter. 477/499: loss=13.471813066884822, w0=72.80000000000014, w1=13.025382968027667\n",
      "SubSGD iter. 478/499: loss=39.034413161941686, w0=73.50000000000014, w1=12.339942858662237\n",
      "SubSGD iter. 479/499: loss=3.956765825203288, w0=74.20000000000014, w1=12.721445834726302\n",
      "SubSGD iter. 480/499: loss=9.327939143641565, w0=73.50000000000014, w1=13.468093384470807\n",
      "SubSGD iter. 481/499: loss=4.545398684361117, w0=72.80000000000014, w1=13.481221615358786\n",
      "SubSGD iter. 482/499: loss=83.29394917652571, w0=73.50000000000014, w1=14.028960205548596\n",
      "SubSGD iter. 483/499: loss=9.625559802534939, w0=74.20000000000014, w1=14.563978997525549\n",
      "SubSGD iter. 484/499: loss=15.37360531352207, w0=73.50000000000014, w1=14.14481050831519\n",
      "SubSGD iter. 485/499: loss=11.070721289411848, w0=74.20000000000014, w1=14.742110696249288\n",
      "SubSGD iter. 486/499: loss=12.318433920476547, w0=74.90000000000015, w1=14.994976758568454\n",
      "SubSGD iter. 487/499: loss=0.023693656478614596, w0=74.20000000000014, w1=13.991383953616163\n",
      "SubSGD iter. 488/499: loss=7.9829959700646045, w0=73.50000000000014, w1=13.218451940976266\n",
      "SubSGD iter. 489/499: loss=5.943751377564778, w0=74.20000000000014, w1=13.616980643005698\n",
      "SubSGD iter. 490/499: loss=1.1552717648868973, w0=73.50000000000014, w1=14.89568219827516\n",
      "SubSGD iter. 491/499: loss=5.0330989601394105, w0=74.20000000000014, w1=14.035268026523712\n",
      "SubSGD iter. 492/499: loss=47.759437318254946, w0=74.90000000000015, w1=14.838490852493306\n",
      "SubSGD iter. 493/499: loss=36.791223687179226, w0=74.20000000000014, w1=15.584639609733552\n",
      "SubSGD iter. 494/499: loss=22.942600278116306, w0=73.50000000000014, w1=14.69756175588427\n",
      "SubSGD iter. 495/499: loss=11.325040663417882, w0=72.80000000000014, w1=14.416817142980662\n",
      "SubSGD iter. 496/499: loss=4.499469605917786, w0=73.50000000000014, w1=13.972528447009347\n",
      "SubSGD iter. 497/499: loss=0.4061517528713593, w0=72.80000000000014, w1=13.858026846935633\n",
      "SubSGD iter. 498/499: loss=41.401256654545186, w0=73.50000000000014, w1=13.360168063956129\n",
      "SubSGD iter. 499/499: loss=35.170195816591665, w0=72.80000000000014, w1=13.309755912352008\n",
      "SubSGD: execution time=0.293 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1028adf2b65e494380399b17e57d3fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses, subsgd_ws, grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight, n_iter)\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {
    "d2b2c3aea192430e81437f33ba0b0e69": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "e4a6a7a70ccd42ddb112989c04f2ed3f": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
