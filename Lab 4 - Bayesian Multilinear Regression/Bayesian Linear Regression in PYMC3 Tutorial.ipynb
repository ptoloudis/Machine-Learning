{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Bayesian Linear Regression in PYMC3 Tutorial**\n\nThis is a very simple tutorial on using PYMC3 for Bayesian linear regression, with an estimation of the posterior probability distributions.  It was adopted from the PYMC3 getting started documentation [https://docs.pymc.io/notebooks/getting_started.html](https://docs.pymc.io/notebooks/getting_started.html).","metadata":{}},{"cell_type":"code","source":"import pymc3 as pm\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-darkgrid')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-03T13:55:33.806004Z","iopub.execute_input":"2023-04-03T13:55:33.806397Z","iopub.status.idle":"2023-04-03T13:55:39.448512Z","shell.execute_reply.started":"2023-04-03T13:55:33.806351Z","shell.execute_reply":"2023-04-03T13:55:39.447273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's create some data for our regression.  Our true values are:\n* $\\alpha = 1$\n* $\\sigma = 1$\n* $\\beta = [1, 2.5]$\n\nOur outcome variable is:\n$$ Y = \\alpha + \\beta_1 X_1 + \\beta_2 X_2 + N(0,\\sigma).$$","metadata":{}},{"cell_type":"code","source":"# Initialize random number generator\nnp.random.seed(123)\n\n# True parameter values\nalpha, sigma = 1, 1\nbeta = [1, 2.5]\n\n# Size of dataset\nsize = 1000\n\n# Predictor variable\nX1 = np.random.randn(size)\nX2 = np.random.randn(size) * 0.2\n\n# Simulate outcome variable\nY = alpha + beta[0]*X1 + beta[1]*X2 + np.random.randn(size)*sigma","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-04-03T13:55:39.454231Z","iopub.execute_input":"2023-04-03T13:55:39.456457Z","iopub.status.idle":"2023-04-03T13:55:39.470222Z","shell.execute_reply.started":"2023-04-03T13:55:39.456405Z","shell.execute_reply":"2023-04-03T13:55:39.469192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here is a quick plot of our data.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, sharex=True, figsize=(10,4))\naxes[0].scatter(X1, Y)\naxes[1].scatter(X2, Y)\naxes[0].set_ylabel('Y'); axes[0].set_xlabel('X1'); axes[1].set_xlabel('X2');","metadata":{"execution":{"iopub.status.busy":"2023-04-03T13:55:39.475338Z","iopub.execute_input":"2023-04-03T13:55:39.477997Z","iopub.status.idle":"2023-04-03T13:55:39.833992Z","shell.execute_reply.started":"2023-04-03T13:55:39.477946Z","shell.execute_reply":"2023-04-03T13:55:39.833025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we build the model.\n\nThe prior distributions are:\n* $\\alpha \\sim \\mathcal{N}(\\mu=0,\\sigma=10)$\n* $\\beta[i] \\sim \\mathcal{N}(\\mu=0,\\sigma=10)$, where $i=1,2$\n* $\\sigma \\sim \\textrm{half-normal}(\\sigma=1)$\n\nWe define the unobserved variable rate, which is a function of the year:\n\\begin{equation}\n  \\mu = \\alpha + \\beta[0]*X1 + \\beta[1]*X2\n\\end{equation}\n\nOur likelihood function in Bayes theorem is a Poisson distribution on the number of disasters, each year.  This can be written as:\n\\begin{equation}\n  \\text{Y}\\sim \\mathcal{N}(\\mu=\\mu,\\sigma=\\sigma).\n\\end{equation}","metadata":{}},{"cell_type":"code","source":"basic_model = pm.Model()\n\nwith basic_model:\n\n    # Priors for unknown model parameters\n    alpha = pm.Normal('alpha', mu=0, sigma=100)\n    beta = pm.Normal('beta', mu=0, sigma=100, shape=2)\n    sigma = pm.HalfNormal('sigma', sigma=100)\n\n    # Expected value of outcome\n    mu = alpha + beta[0]*X1 + beta[1]*X2\n\n    # Likelihood (sampling distribution) of observations\n    Y_obs = pm.Normal('Y_obs', mu=mu, sigma=sigma, observed=Y)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T13:55:39.838148Z","iopub.execute_input":"2023-04-03T13:55:39.840144Z","iopub.status.idle":"2023-04-03T13:56:08.341166Z","shell.execute_reply.started":"2023-04-03T13:55:39.840098Z","shell.execute_reply":"2023-04-03T13:56:08.339969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we take 5000 random MCMC samples.  The defualt PYMC3 sampler is the Hamiltonian MC No U-Turn Sampler (NUTS), which is almost always a good choice.","metadata":{}},{"cell_type":"code","source":"with basic_model:\n    # draw 5000 posterior samples\n    trace = pm.sample(5000)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T13:56:08.347394Z","iopub.execute_input":"2023-04-03T13:56:08.349850Z","iopub.status.idle":"2023-04-03T13:57:17.966069Z","shell.execute_reply.started":"2023-04-03T13:56:08.349787Z","shell.execute_reply":"2023-04-03T13:57:17.964618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The traceplot is the standard good way to view the posterior probability distributions along with theMCMC samples.","metadata":{}},{"cell_type":"code","source":"pm.traceplot(trace);","metadata":{"execution":{"iopub.status.busy":"2023-04-03T13:57:17.973517Z","iopub.execute_input":"2023-04-03T13:57:17.976813Z","iopub.status.idle":"2023-04-03T13:57:24.005129Z","shell.execute_reply.started":"2023-04-03T13:57:17.976703Z","shell.execute_reply":"2023-04-03T13:57:24.003299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a built-in summary function as well.","metadata":{}},{"cell_type":"code","source":"pm.summary(trace).round(2)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T13:57:24.008694Z","iopub.execute_input":"2023-04-03T13:57:24.009816Z","iopub.status.idle":"2023-04-03T13:57:27.083715Z","shell.execute_reply.started":"2023-04-03T13:57:24.009773Z","shell.execute_reply":"2023-04-03T13:57:27.082725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here are some 2-d plots of joint probability distributions.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(9,7))\nsns.jointplot(trace['beta'][:,0], trace['beta'][:,1], kind=\"hex\", color=\"#4CB391\")\nplt.xlabel(\"beta[0]\")\nplt.ylabel(\"beta[1]\");\nplt.show()\n\nplt.figure(figsize=(9,7))\nsns.jointplot(trace['alpha'], trace['sigma'], kind=\"hex\", color=\"#4CB391\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"sigma\");\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-03T13:57:27.088281Z","iopub.execute_input":"2023-04-03T13:57:27.090589Z","iopub.status.idle":"2023-04-03T13:57:29.138093Z","shell.execute_reply.started":"2023-04-03T13:57:27.090533Z","shell.execute_reply":"2023-04-03T13:57:29.137044Z"},"trusted":true},"execution_count":null,"outputs":[]}]}