<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Module 3: The Reverse Mode of Automatic Differentiation &#8212; Auto-eD  documentation</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/s4defs-roles.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Module 4: Beyond the Basics: Extensions and Software Development" href="mod4.html" />
    <link rel="prev" title="Module 2: Deeper Into Forward Mode" href="mod2.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <blockquote>
<div></div></blockquote>
<div class="section" id="module-3-the-reverse-mode-of-automatic-differentiation">
<h1>Module 3: The Reverse Mode of Automatic Differentiation<a class="headerlink" href="#module-3-the-reverse-mode-of-automatic-differentiation" title="Permalink to this headline">¶</a></h1>
<p>So far we have considered one mode of automatic differentiation, the forward mode.  In forward mode, we carried derivatives along
as we traversed the graph so that the graph itself did not need to be explicitly stored in memory.</p>
<p>In reverse mode, we build the graph and store partial derivative information at each node but do not compute the full derivative with the chain rule
until the backward pass of the graph. We will see that both approaches have computational advantages over each other for
different types of problems.</p>
<div class="section" id="i-the-basics-of-reverse-mode">
<h2>I. The Basics of Reverse Mode<a class="headerlink" href="#i-the-basics-of-reverse-mode" title="Permalink to this headline">¶</a></h2>
<p>As in forward mode, reverse mode still relies on the underlying computational graph structure of functions. As we will see
using the visualization tool, the same graph can be used for forward and reverse mode, but what is different is the direction that derivative
information is propagated. Recall that in forward mode, we passed derivative information forward to store the
derivative at each node.</p>
<p>In reverse mode, instead of storing full derivative information at each node, <em>only the partial derivatives of nodes relative
to its children are stored</em>.  For example, if node <span class="math">\(x_3\)</span> has inputs nodes <span class="math">\(x_1\)</span> and <span class="math">\(x_2\)</span>, only the partial
derivatives <span class="math">\(\frac{\partial x_3}{\partial x_1}\)</span> and <span class="math">\(\frac{\partial x_3}{\partial x_2}\)</span> are stored. Contrast
this with forward mode, where for a function with inputs <span class="math">\(x\)</span> and <span class="math">\(y\)</span>, this node would store <span class="math">\(\frac{\partial x_3}{\partial
x}\)</span> and <span class="math">\(\frac{\partial x_3}{\partial y}\)</span> via the chain rule.</p>
<p>The reverse mode consists of two passes through the graph. The forward pass first builds the computational graph while
storing just the partial derivative information. The reverse pass then starts at the output node and traverses the graph in
the reverse direction to find the full partial derivatives.</p>
<p>The &#8220;bar notation&#8221; is commonly used to denote our backward pass tangents, <span class="math">\(\bar{x_i} = \frac{\partial f}{\partial
x_i}\)</span>. These are sometimes also called the adjoint variable.  At the final node in the graph, <span class="math">\(f = x_N\)</span>, we have
<span class="math">\(\bar{x_N} = \frac{\partial f}{\partial x_N} = 1\)</span>. We then traverse backward through the graph to construct the partial
derivative from the chain rule. <span class="math">\(\bar{x_{N-1}}  = \bar{x_N}\frac{\partial x_N}{\partial x_{N-1}}\)</span>. Note that the
partial derivative is exactly the value that has already been stored by the forward pass of the graph.</p>
<p>This process is relatively straightforward for nodes with only one child. When we encounter nodes with multiple children, we
must perform a summation over the children, which follows directly from the multivariate chain rule.</p>
<p>For <span class="math">\(x_i\)</span> with children <span class="math">\(x_j\)</span> and <span class="math">\(x_k\)</span>, we have</p>
<div class="math">
\[\bar{x_i} = \bar{x_j}\frac{\partial x_j}{\partial x_i} + \bar{x_k}\frac{\partial x_k}{\partial x_i}.\]</div>
</div>
<div class="section" id="ii-summary-sketch-of-reverse-mode">
<h2>II. Summary Sketch of Reverse Mode<a class="headerlink" href="#ii-summary-sketch-of-reverse-mode" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li>Create the evaluation graph</li>
<li>The forward pass does function evaluations</li>
<li><dl class="first docutils">
<dt>The forward pass also saves the partial derivatives of the elementary function at each step</dt>
<dd><ul class="first last">
<li><strong>It does not do the chain rule!</strong></li>
<li>It only stores the partial derivatives</li>
<li><dl class="first docutils">
<dt>Examples:</dt>
<dd><ul class="first last">
<li>If <span class="math">\(v_3 = v_1 v_2\)</span> is a node, then we store <span class="math">\(\dfrac{\partial v_3}{\partial v_1}\)</span> and
<span class="math">\(\dfrac{\partial v_3}{\partial v_2}\)</span>. That&#8217;s it.</li>
<li>If <span class="math">\(v_3 = \sin(v_2)\)</span> is a node, then we store <span class="math">\(\cos(v_2)\)</span>. Notice that there is no <span class="math">\(\dot{v}_{2}\)</span>.</li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li>The reverse pass starts with <span class="math">\(\overline{v}_{N} = \dfrac{\partial f}{\partial v_{N}} = 1\)</span> (since <span class="math">\(f\)</span> is <span class="math">\(v_{N}\)</span>).</li>
<li><dl class="first docutils">
<dt>Next, the reverse pass gets <span class="math">\(\overline{v}_{N-1} = \dfrac{\partial f}{\partial v_{N}}\dfrac{\partial v_{N}}{\partial v_{N-1}}\)</span>.</dt>
<dd><ul class="first last">
<li><strong>Note:</strong> <span class="math">\(\dfrac{\partial v_{N}}{\partial v_{N-1}}\)</span> is already stored from the forward pass.</li>
</ul>
</dd>
</dl>
</li>
<li>The only trick occurs when we get to a branch in the graph. That is, when the node we&#8217;re on has more than one child. In</li>
</ol>
<blockquote>
<div><p>that case, we sum the two paths. For example, if <span class="math">\(v_3\)</span> has <span class="math">\(v_4\)</span> and <span class="math">\(v_5\)</span> as children, then we do:</p>
<blockquote>
<div><div class="math">
\[\overline{v}_{3} = \dfrac{\partial f}{\partial v_{3}} = \dfrac{\partial f}{\partial v_{4}}\dfrac{\partial
v_{4}}{\partial v_{3}} + \dfrac{\partial f}{\partial v_{5}}\dfrac{\partial v_{5}}{\partial v_{3}}\]</div>
<ul class="simple">
<li><strong>Note:</strong> This summation is a manifestation of the chain rule.</li>
</ul>
</div></blockquote>
</div></blockquote>
</div>
<div class="section" id="iii-the-basic-equations">
<h2>III. The Basic Equations<a class="headerlink" href="#iii-the-basic-equations" title="Permalink to this headline">¶</a></h2>
<p>The partial derivative of <span class="math">\(f\)</span> with respect to <span class="math">\(u_{i}\)</span> can be written as (see <a class="reference external" href="refs.html">Nocedal and Wright</a>, pg. 180):</p>
<div class="math">
\[\dfrac{\partial f}{\partial u_{i}} = \sum_{j\text{ a child of } i}{\dfrac{\partial f}{\partial u_{j}}\dfrac{\partial
u_{j}}{\partial u_{i}}}.\]</div>
<p>At each node <span class="math">\(i\)</span> we compute</p>
<div class="math">
\[\overline{u}_{i} += \dfrac{\partial f}{\partial u_{j}}\dfrac{\partial u_{j}}{\partial u_{i}}.\]</div>
<p>The <span class="math">\(\overline{u}_{i}\)</span> variable stores the current value of the partial derivative at node <span class="math">\(i\)</span>. As mentioned
previously, it is sometimes called the adjoint variable.</p>
<p>Note that in our notation <span class="math">\(u_{i}\)</span> could be an input variable (e.g. <span class="math">\(x_{i}\)</span>) or an intermediate variable (e.g.
<span class="math">\(v_{i}\)</span>).</p>
</div>
<div class="section" id="iv-an-example-for-intuition">
<h2>IV. An Example for Intuition<a class="headerlink" href="#iv-an-example-for-intuition" title="Permalink to this headline">¶</a></h2>
<p>Let&#8217;s try to evaluate the function</p>
<div class="math">
\[f(x,y) = xy + \exp(xy)\]</div>
<p>and its gradient at the point <span class="math">\((1,2)\)</span>. We&#8217;ll use reverse mode this time. Here is a picture of the computational graph,</p>
<img alt="_images/Reverse-Example.PNG" src="_images/Reverse-Example.PNG" />
<p>and the corresponding table,</p>
<img alt="_images/Reverse-Example-Table.PNG" src="_images/Reverse-Example-Table.PNG" />
<div class="section" id="step-1">
<h3>Step 1<a class="headerlink" href="#step-1" title="Permalink to this headline">¶</a></h3>
<p>The first step is to generate the forward trace and calculate the partial derivatives of a node with respect to its
children. Note that this time we must save the graph.</p>
</div>
<div class="section" id="step-2">
<h3>Step 2<a class="headerlink" href="#step-2" title="Permalink to this headline">¶</a></h3>
<p>Next, we start at <span class="math">\(v_{3}\)</span> and start calculating the chain rule. We have</p>
<div class="math">
\[\overline{v}_{3} = \dfrac{\partial f}{\partial v_{3}} = 1.\]</div>
<img alt="_images/v3.PNG" src="_images/v3.PNG" />
</div>
<div class="section" id="step-3">
<h3>Step 3<a class="headerlink" href="#step-3" title="Permalink to this headline">¶</a></h3>
<div class="math">
\[\overline{v}_{2} = \dfrac{\partial f}{\partial v_{3}}\dfrac{\partial v_{3}}{\partial v_{2}} = 1 \cdot 1 = 1.\]</div>
<img alt="_images/v2.PNG" src="_images/v2.PNG" />
</div>
<div class="section" id="step-4">
<h3>Step 4<a class="headerlink" href="#step-4" title="Permalink to this headline">¶</a></h3>
<div class="math">
\[\overline{v}_{1} = \dfrac{\partial f}{\partial v_{3}}\dfrac{\partial v_{3}}{\partial v_{1}} + \dfrac{\partial
  f}{\partial v_{2}}\dfrac{\partial v_{2}}{\partial v_{1}}= 1 \cdot 1 + 1 \cdot e^{2} = 1 + e^{2}.\]</div>
<p>Note that we had to do a sum over the childen this time!</p>
<img alt="_images/v1.PNG" src="_images/v1.PNG" />
</div>
<div class="section" id="step-5">
<h3>Step 5<a class="headerlink" href="#step-5" title="Permalink to this headline">¶</a></h3>
<div class="math">
\[\overline{x}_{2} = \dfrac{\partial f}{\partial v_{1}}\dfrac{\partial v_{1}}{\partial x_{2}} = (1 + e^{2})x_{1} = 1 +
 e^{2} = \dfrac{\partial f}{\partial y}.\]</div>
<img alt="_images/x2.PNG" src="_images/x2.PNG" />
</div>
<div class="section" id="step-6">
<h3>Step 6<a class="headerlink" href="#step-6" title="Permalink to this headline">¶</a></h3>
<div class="math">
\[\overline{x}_{1} = \dfrac{\partial f}{\partial v_{1}}\dfrac{\partial v_{1}}{\partial x_{1}} = (1 + e^{2})x_{2} = 2 +
 2e^{2} = \dfrac{\partial f}{\partial x}.\]</div>
<img alt="_images/x1.PNG" src="_images/x1.PNG" />
<p>You should check that these results match those from taking the symbolic derivative and evaluating it at the desired point.</p>
</div>
</div>
<div class="section" id="v-practice-with-the-visualization-tool">
<h2>V. Practice with the Visualization Tool<a class="headerlink" href="#v-practice-with-the-visualization-tool" title="Permalink to this headline">¶</a></h2>
<p>Let&#8217;s revisit our typical example. As with forward mode, we input the function into the interface in the same way and can
compute the function value and derivative, but now we know a little bit about what reverse mode computes.</p>
<p>Let&#8217;s start with the same example we analyzed for forward mode, <span class="math">\(f(x) = x-\exp(-2\sin(4x)^2)\)</span>. Input it into the visualization tool in
the same way that you did in the <a class="reference external" href="mod1.html#iv-a-first-demo-of-automatic-differentiation">first module</a>.</p>
<p>This time, focus on the right half of the visualization page. At the top right, you&#8217;ll see a graph that looks very similar to the one
produced in forward mode. Notice that the only difference is the direction of the arrows, representing the fact that
derivatives are propagated in different directions.</p>
<img alt="_images/Step4.PNG" src="_images/Step4.PNG" />
<p>Now let&#8217;s dynamically visualize the process of reverse mode. In the bottom right, press the &#8220;df/dx&#8221; button. Use the &#8220;Next&#8221;
button to step through the process of reverse mode. At each step, the edge that the computation traverses is highlighted.</p>
<p>Try the example with a function with multiple inputs, <span class="math">\(f(x,y) = xy+\exp(xy)\)</span>. Recall that this function has a branch in its underlying
graph structure. This time when dynamically visualizing the reverse mode, you should see that the computation has to trace
through both branches to pick up the stored partial derivatives for the computation of the derivatives.</p>
<p><strong>Key Takeaways</strong></p>
<ul class="simple">
<li>Reverse mode and forward mode propagate the derivative in different directions.</li>
<li>The underlying graph structure of the function is the same for both modes of automatic differentiation.</li>
<li>Reverse mode computes derivatives by making a backward pass starting at the output.</li>
</ul>
</div>
<div class="section" id="vi-more-theory">
<h2>VI. More Theory<a class="headerlink" href="#vi-more-theory" title="Permalink to this headline">¶</a></h2>
<p>In the previous module, we demonstrated that forward mode computes the Jacobian vector product <span class="math">\(Jp\)</span>. In contrast,
reverse mode computes <span class="math">\(J^Tp\)</span> where <span class="math">\(J^{T}\)</span> is the transpose of the Jacobian. This seemingly small difference can
result in different operation counts for different kinds of problems.</p>
<div class="section" id="comment">
<h3>Comment<a class="headerlink" href="#comment" title="Permalink to this headline">¶</a></h3>
<p>Backpropagation is a special case of the reverse mode of automatic differentiation where the function in which we are
interested in taking derivatives is a scalar function that represents the error between the output and the true value.</p>
</div>
</div>
<div class="section" id="vii-a-comparison-of-forward-and-reverse-mode">
<h2>VII. A Comparison of Forward and Reverse Mode<a class="headerlink" href="#vii-a-comparison-of-forward-and-reverse-mode" title="Permalink to this headline">¶</a></h2>
<p>As the names suggest, the primary difference between forward and reverse mode is the direciton in which the computational
graph is traversed, as we saw with the visualization tool. This has implications for the computational efficiency of the two
approaches.</p>
<p>As we just stated, reverse mode computes <span class="math">\(J^Tp\)</span>, while in <a class="reference external" href="mod2.html#what-does-forward-mode-compute">Module 2</a>, we learned that forward mode computes <span class="math">\(Jp\)</span>.
Although we didn&#8217;t go too deep into it, the implication of this difference is that reverse mode will be more efficient (require fewer operations) for functions with a fewer number of outputs and many inputs, while forward mode will be more efficient for functions with many outputs and fewer inputs.</p>
<div class="section" id="demo-a-comparison-of-forward-and-reverse-mode">
<h3>Demo: A Comparison of Forward and Reverse Mode<a class="headerlink" href="#demo-a-comparison-of-forward-and-reverse-mode" title="Permalink to this headline">¶</a></h3>
<p>Consider the function <span class="math">\(f(w_1, w_2, w_3, w_4, w_5) = w_1w_2w_3w_4w_5\)</span>. We want to compare the process of computing the
partial derivatives in forward and reverse mode at the point <span class="math">\((2, 1, 1, 1, 1)\)</span>.  Let&#8217;s start with reverse mode, where
we do not store the results of the chain rule but just the values of the partial derivatives at each step.</p>
<table border="1" class="colwidths-given docutils">
<colgroup>
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Node</th>
<th class="head">Current Value</th>
<th class="head">Numerical Value</th>
<th class="head"><span class="math">\(\partial_1\)</span></th>
<th class="head"><span class="math">\(\partial_1\)</span> Value</th>
<th class="head"><span class="math">\(\partial_2\)</span></th>
<th class="head"><span class="math">\(\partial_2\)</span> Value</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><span class="math">\(x_1\)</span></td>
<td><span class="math">\(x_1\)</span></td>
<td>2</td>
<td>1</td>
<td>1</td>
<td><ul class="first last simple">
<li></li>
</ul>
</td>
<td><ul class="first last simple">
<li></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><span class="math">\(x_2\)</span></td>
<td><span class="math">\(x_2\)</span></td>
<td>1</td>
<td>1</td>
<td>1</td>
<td><ul class="first last simple">
<li></li>
</ul>
</td>
<td><ul class="first last simple">
<li></li>
</ul>
</td>
</tr>
<tr class="row-even"><td><span class="math">\(x_3\)</span></td>
<td><span class="math">\(x_3\)</span></td>
<td>1</td>
<td>1</td>
<td>1</td>
<td><ul class="first last simple">
<li></li>
</ul>
</td>
<td><ul class="first last simple">
<li></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><span class="math">\(x_4\)</span></td>
<td><span class="math">\(x_4\)</span></td>
<td>1</td>
<td>1</td>
<td>1</td>
<td><ul class="first last simple">
<li></li>
</ul>
</td>
<td><ul class="first last simple">
<li></li>
</ul>
</td>
</tr>
<tr class="row-even"><td><span class="math">\(x_5\)</span></td>
<td><span class="math">\(x_5\)</span></td>
<td>1</td>
<td>1</td>
<td>1</td>
<td><ul class="first last simple">
<li></li>
</ul>
</td>
<td><ul class="first last simple">
<li></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><span class="math">\(x_6\)</span></td>
<td><span class="math">\(x_4x_5\)</span></td>
<td>1</td>
<td><span class="math">\(x_5\)</span></td>
<td>1</td>
<td><span class="math">\(x_4\)</span></td>
<td>1</td>
</tr>
<tr class="row-even"><td><span class="math">\(x_7\)</span></td>
<td><span class="math">\(x_3x_6\)</span></td>
<td>1</td>
<td><span class="math">\(x_6\)</span></td>
<td>1</td>
<td><span class="math">\(x_3\)</span></td>
<td>1</td>
</tr>
<tr class="row-odd"><td><span class="math">\(x_8\)</span></td>
<td><span class="math">\(x_2x_7\)</span></td>
<td>1</td>
<td><span class="math">\(x_7\)</span></td>
<td>1</td>
<td><span class="math">\(x_2\)</span></td>
<td>1</td>
</tr>
<tr class="row-even"><td><span class="math">\(x_9\)</span></td>
<td><span class="math">\(x_1x_8\)</span></td>
<td>2</td>
<td><span class="math">\(x_8\)</span></td>
<td>1</td>
<td><span class="math">\(x_1\)</span></td>
<td>2</td>
</tr>
</tbody>
</table>
<p>To compute the derivatives, we will now traverse through the graph, picking up the partial derivatives, using our update
equations. You can visualize this graph traversal by using the dynamic visualization tool.</p>
<div class="math">
\[ \begin{align}\begin{aligned}\bar{x_9} &amp;= \frac{\partial f}{\partial x_9} = 1\\\bar{x_8} &amp;= \frac{\partial f}{\partial x_9}\frac{\partial x_9}{\partial x_8} = 1 \cdot 2 = 2\\\bar{x_7} &amp;= \frac{\partial f}{\partial x_8}\frac{\partial x_8}{\partial x_7} = 2 \cdot 1 = 2\\\bar{x_6} &amp;= \frac{\partial f}{\partial x_7}\frac{\partial x_7}{\partial x_6} = 2 \cdot 1 = 2\\\bar{x_5} &amp;= \frac{\partial f}{\partial x_6}\frac{\partial x_6}{\partial x_5} = 2 \cdot 1 = 2\\\bar{x_4} &amp;= \frac{\partial f}{\partial x_6}\frac{\partial x_6}{\partial x_4} = 2 \cdot 1 = 2\\\bar{x_3} &amp;= \frac{\partial f}{\partial x_7}\frac{\partial x_7}{\partial x_3} = 2 \cdot 1 = 2\\\bar{x_2} &amp;= \frac{\partial f}{\partial x_8}\frac{\partial x_8}{\partial x_2} = 2 \cdot 1 = 2\\\bar{x_1} &amp;= \frac{\partial f}{\partial x_9}\frac{\partial x_9}{\partial x_1} = 1 \cdot 1 = 1\end{aligned}\end{align} \]</div>
<p>As we learned in the previous module, we could have used forward mode to compute the same values. We know that we can use the
same graph structure for both directions, so let&#8217;s compare the computational table for forward mode.</p>
<table border="1" class="colwidths-given docutils">
<colgroup>
<col width="8%" />
<col width="17%" />
<col width="17%" />
<col width="17%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Node</th>
<th class="head">Elementary Function</th>
<th class="head">Numerical Value</th>
<th class="head">Derivative</th>
<th class="head"><span class="math">\(\partial_1\)</span></th>
<th class="head"><span class="math">\(\partial_2\)</span></th>
<th class="head"><span class="math">\(\partial_3\)</span></th>
<th class="head"><span class="math">\(\partial_4\)</span></th>
<th class="head"><span class="math">\(\partial_5\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><span class="math">\(x_1\)</span></td>
<td><span class="math">\(x_1\)</span></td>
<td>2</td>
<td><span class="math">\(\dot{x_1}\)</span></td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="row-odd"><td><span class="math">\(x_2\)</span></td>
<td><span class="math">\(x_2\)</span></td>
<td>1</td>
<td><span class="math">\(\dot{x_2}\)</span></td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="row-even"><td><span class="math">\(x_3\)</span></td>
<td><span class="math">\(x_3\)</span></td>
<td>1</td>
<td><span class="math">\(\dot{x_3}\)</span></td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="row-odd"><td><span class="math">\(x_4\)</span></td>
<td><span class="math">\(x_4\)</span></td>
<td>1</td>
<td><span class="math">\(\dot{x_4}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="row-even"><td><span class="math">\(x_5\)</span></td>
<td><span class="math">\(x_5\)</span></td>
<td>1</td>
<td><span class="math">\(\dot{x_5}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="row-odd"><td><span class="math">\(x_6\)</span></td>
<td><span class="math">\(x_4x_5\)</span></td>
<td>1</td>
<td><span class="math">\(x_4\dot{x_5}+\dot{x_4}x_5\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="row-even"><td><span class="math">\(x_7\)</span></td>
<td><span class="math">\(x_3x_6\)</span></td>
<td>1</td>
<td><span class="math">\(x_3\dot{x_6}+\dot{x_3}x_6\)</span></td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="row-odd"><td><span class="math">\(x_8\)</span></td>
<td><span class="math">\(x_2x_7\)</span></td>
<td>1</td>
<td><span class="math">\(x_2\dot{x_7}+\dot{x_2}x_7\)</span></td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="row-even"><td><span class="math">\(x_9\)</span></td>
<td><span class="math">\(x_1x_8\)</span></td>
<td>2</td>
<td><span class="math">\(x_1\dot{x_8}+\dot{x_1}x_8\)</span></td>
<td>1</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>Both methods require 4 multiplication steps. Now consider the operations to compute the partial derivatives.</p>
<ul class="simple">
<li>Reverse mode: Required a single multiplication step (the product of the two partial derivatives) at nodes 1-8, for a total of 8 operations.</li>
<li>Forward mode: At nodes 6-9 (4 nodes), we use the product rule to compute the derivative (requiring 3 operations, 2 multiplications and 1
addition) for each of the 5 inputs, for a total of <span class="math">\(4\cdot 3 \cdot 5 = 60\)</span> operations</li>
</ul>
<p>This example demonstrates that in cases with many inputs and few outputs, reverse mode is more computationally efficient than forward mode.</p>
</div>
</div>
<div class="section" id="viii-going-forward">
<h2>VIII. Going Forward<a class="headerlink" href="#viii-going-forward" title="Permalink to this headline">¶</a></h2>
<p>In the <a class="reference external" href="mod4.html">next module</a>, we explore an alternate interpretation of automatic differentiation in terms of dual numbers and consider
questions of implementation in software.</p>
<p>Other extensions for further reading include automatic differentiation for higher order derivatives, including computing
Hessians, and algorithmic differentiation of computer programs. We can also consider the efficiency of the algorithms in
terms of memory and efficient graph storage, access, and traversal. Such efficiency may be better achieved in cases where the
Jacobian and Hessian are sparse. Other work has explored using a mixture of forward and reverse mode for computations.</p>
</div>
<div class="section" id="ix-exercise">
<h2>IX. Exercise<a class="headerlink" href="#ix-exercise" title="Permalink to this headline">¶</a></h2>
<p>Let&#8217;s return to the function that we previously used the visualization tool to dynamically traverse the steps of the reverse mode.</p>
<div class="math">
\[f(x, y) = xy + \exp(xy)\]</div>
<p>Write out the reverse mode table, which stores only partial derivative information, and use it to compute the full derivative in reverse mode at the point <span class="math">\((1,2)\)</span>.
You can return to the dynamic visualization tool to follow the steps that your calculation performs as you traverse the graph from output to input.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Module 3: The Reverse Mode of Automatic Differentiation</a><ul>
<li><a class="reference internal" href="#i-the-basics-of-reverse-mode">I. The Basics of Reverse Mode</a></li>
<li><a class="reference internal" href="#ii-summary-sketch-of-reverse-mode">II. Summary Sketch of Reverse Mode</a></li>
<li><a class="reference internal" href="#iii-the-basic-equations">III. The Basic Equations</a></li>
<li><a class="reference internal" href="#iv-an-example-for-intuition">IV. An Example for Intuition</a><ul>
<li><a class="reference internal" href="#step-1">Step 1</a></li>
<li><a class="reference internal" href="#step-2">Step 2</a></li>
<li><a class="reference internal" href="#step-3">Step 3</a></li>
<li><a class="reference internal" href="#step-4">Step 4</a></li>
<li><a class="reference internal" href="#step-5">Step 5</a></li>
<li><a class="reference internal" href="#step-6">Step 6</a></li>
</ul>
</li>
<li><a class="reference internal" href="#v-practice-with-the-visualization-tool">V. Practice with the Visualization Tool</a></li>
<li><a class="reference internal" href="#vi-more-theory">VI. More Theory</a><ul>
<li><a class="reference internal" href="#comment">Comment</a></li>
</ul>
</li>
<li><a class="reference internal" href="#vii-a-comparison-of-forward-and-reverse-mode">VII. A Comparison of Forward and Reverse Mode</a><ul>
<li><a class="reference internal" href="#demo-a-comparison-of-forward-and-reverse-mode">Demo: A Comparison of Forward and Reverse Mode</a></li>
</ul>
</li>
<li><a class="reference internal" href="#viii-going-forward">VIII. Going Forward</a></li>
<li><a class="reference internal" href="#ix-exercise">IX. Exercise</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="mod2.html" title="previous chapter">Module 2: Deeper Into Forward Mode</a></li>
      <li>Next: <a href="mod4.html" title="next chapter">Module 4: Beyond the Basics: Extensions and Software Development</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/mod3.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Lindsey Brown, Rachel Moon, and David Sondak.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.5.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/mod3.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>